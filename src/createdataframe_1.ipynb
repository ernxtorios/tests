{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7c5d95",
   "metadata": {},
   "source": [
    "# Crear dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a6ac00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4434296",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"createDataFrameOverview1\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a5314",
   "metadata": {},
   "source": [
    "### Crear un DataFrame a partir de una lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b3130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|       _1| _2|\n",
      "+---------+---+\n",
      "|Moyobamba|  0|\n",
      "|  Calzada|  1|\n",
      "|   Habana|  2|\n",
      "|Jepelacio|  3|\n",
      "|  Soritor|  4|\n",
      "|  Yantalo|  5|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([('Moyobamba', 0),\n",
    "                      ('Calzada', 1),\n",
    "                      ('Habana', 2),\n",
    "                      ('Jepelacio', 3),\n",
    "                      ('Soritor', 4),\n",
    "                      ('Yantalo', 5)]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9dea1",
   "metadata": {},
   "source": [
    "### Crear un DataFrame a partir de una lista de diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a471bae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "| distrito| id|\n",
      "+---------+---+\n",
      "|Moyobamba|  0|\n",
      "|  Calzada|  1|\n",
      "|   Habana|  2|\n",
      "|Jepelacio|  3|\n",
      "|  Soritor|  4|\n",
      "|  Yantalo|  5|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moyobamba = [\n",
    "    {'distrito': 'Moyobamba', 'id': 0},\n",
    "    {'distrito': 'Calzada', 'id': 1},\n",
    "    {'distrito': 'Habana', 'id': 2},\n",
    "    {'distrito': 'Jepelacio', 'id': 3},\n",
    "    {'distrito': 'Soritor', 'id': 4},\n",
    "    {'distrito': 'Yantalo', 'id': 5}\n",
    "]\n",
    "\n",
    "spark.createDataFrame(moyobamba).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac95cbd",
   "metadata": {},
   "source": [
    "### Crear un DataFrame con nombres de columnas especificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe7787f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "| distrito| id|\n",
      "+---------+---+\n",
      "|Moyobamba|  0|\n",
      "|  Calzada|  1|\n",
      "|   Habana|  2|\n",
      "|Jepelacio|  3|\n",
      "|  Soritor|  4|\n",
      "|  Yantalo|  5|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([('Moyobamba', 0),\n",
    "                      ('Calzada', 1),\n",
    "                      ('Habana', 2),\n",
    "                      ('Jepelacio', 3),\n",
    "                      ('Soritor', 4),\n",
    "                      ('Yantalo', 5)], ['distrito', 'id']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464edd1c",
   "metadata": {},
   "source": [
    "### Crear un DataFrame con el esquema explícito especificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85da038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "| distrito| id|\n",
      "+---------+---+\n",
      "|Moyobamba|  0|\n",
      "|  Calzada|  1|\n",
      "|   Habana|  2|\n",
      "|Jepelacio|  3|\n",
      "|  Soritor|  4|\n",
      "|  Yantalo|  5|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('distrito', StringType(), True),\n",
    "    StructField('id', IntegerType(), True)\n",
    "])\n",
    "\n",
    "spark.createDataFrame([('Moyobamba', 0),\n",
    "                      ('Calzada', 1),\n",
    "                      ('Habana', 2),\n",
    "                      ('Jepelacio', 3),\n",
    "                      ('Soritor', 4),\n",
    "                      ('Yantalo', 5)], schema).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9c50c",
   "metadata": {},
   "source": [
    "### Crear un DataFrame con el esquema en cadena con formato DDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed74d356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "| distrito| id|\n",
      "+---------+---+\n",
      "|Moyobamba|  0|\n",
      "|  Calzada|  1|\n",
      "|   Habana|  2|\n",
      "|Jepelacio|  3|\n",
      "|  Soritor|  4|\n",
      "|  Yantalo|  5|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([('Moyobamba', 0),\n",
    "                      ('Calzada', 1),\n",
    "                      ('Habana', 2),\n",
    "                      ('Jepelacio', 3),\n",
    "                      ('Soritor', 4),\n",
    "                      ('Yantalo', 5)], \"distrito: string, id: int\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa6fc5",
   "metadata": {},
   "source": [
    "### Crear un DataFrame vacío \n",
    "\n",
    "Al inicializar un DataFrame vacío en PySpark, es obligatorio especificar su esquema, ya que el DataFrame carece de datos a partir de los cuales se pueda inferir el esquema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7882d2af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|distrito| id|\n",
      "+--------+---+\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([], \"distrito: string, id: int\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc2ca9",
   "metadata": {},
   "source": [
    "### Crear un DataFrame a partir de objetos Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e288b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Ernesto| 48|\n",
      "|   Juan| 67|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "Persona = Row('name', 'age')\n",
    "df = spark.createDataFrame([Persona('Ernesto', 48), Persona('Juan', 67)])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d799ed",
   "metadata": {},
   "source": [
    "### Crear un DataFrame a partir de un DataFrame de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e29445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: bigint]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5dad952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(0=1, 1=2)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "spark.createDataFrame(pandas.DataFrame([[1, 2]])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46daa77b-8b62-47f5-aeb5-bbdff6b5e828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
