_hive.hdfs.session.path=/tmp/hive/ernestosegundo/6e0c6736-c50a-421c-bfc7-5bc34a910619
_hive.local.session.path=/tmp/hive/java/ernestosegundo/6e0c6736-c50a-421c-bfc7-5bc34a910619
_hive.tmp_table_space=/tmp/hive/ernestosegundo/6e0c6736-c50a-421c-bfc7-5bc34a910619/_tmp_space.db
datanode.https.port=50475
datanucleus.cache.level2=false
datanucleus.cache.level2.type=none
datanucleus.connectionPool.maxPoolSize=10
datanucleus.connectionPoolingType=HikariCP
datanucleus.identifierFactory=datanucleus1
datanucleus.plugin.pluginRegistryBundleCheck=LOG
datanucleus.rdbms.initializeColumnInfo=NONE
datanucleus.rdbms.useLegacyNativeValueStrategy=true
datanucleus.schema.autoCreateAll=false
datanucleus.schema.validateColumns=false
datanucleus.schema.validateConstraints=false
datanucleus.schema.validateTables=false
datanucleus.storeManagerType=rdbms
datanucleus.transactionIsolation=read-committed
dfs.balancer.address=0.0.0.0:0
dfs.balancer.block-move.timeout=0
dfs.balancer.dispatcherThreads=200
dfs.balancer.getBlocks.min-block-size=10485760
dfs.balancer.getBlocks.size=2147483648
dfs.balancer.keytab.enabled=false
dfs.balancer.max-iteration-time=1200000
dfs.balancer.max-no-move-interval=60000
dfs.balancer.max-size-to-move=10737418240
dfs.balancer.movedWinWidth=5400000
dfs.balancer.moverThreads=1000
dfs.balancer.service.interval=5m
dfs.balancer.service.retries.on.exception=5
dfs.batched.ls.limit=100
dfs.block.access.key.update.interval=600
dfs.block.access.token.enable=false
dfs.block.access.token.lifetime=600
dfs.block.access.token.protobuf.enable=false
dfs.block.invalidate.limit=1000
dfs.block.misreplication.processing.limit=10000
dfs.block.placement.ec.classname=org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant
dfs.block.replicator.classname=org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault
dfs.block.scanner.skip.recent.accessed=false
dfs.block.scanner.volume.bytes.per.second=1048576
dfs.block.scanner.volume.join.timeout.ms=5000
dfs.blockreport.incremental.intervalMsec=0
dfs.blockreport.initialDelay=0
dfs.blockreport.intervalMsec=21600000
dfs.blockreport.split.threshold=1000000
dfs.blocksize=134217728
dfs.bytes-per-checksum=512
dfs.cachereport.intervalMsec=10000
dfs.checksum.combine.mode=MD5MD5CRC
dfs.checksum.ec.socket-timeout=3000
dfs.checksum.type=CRC32C
dfs.client-write-packet-size=65536
dfs.client.block.reader.remote.buffer.size=512
dfs.client.block.write.locateFollowingBlock.initial.delay.ms=400
dfs.client.block.write.locateFollowingBlock.max.delay.ms=60000
dfs.client.block.write.locateFollowingBlock.retries=5
dfs.client.block.write.replace-datanode-on-failure.best-effort=false
dfs.client.block.write.replace-datanode-on-failure.enable=true
dfs.client.block.write.replace-datanode-on-failure.min-replication=0
dfs.client.block.write.replace-datanode-on-failure.policy=DEFAULT
dfs.client.block.write.retries=3
dfs.client.cached.conn.retry=3
dfs.client.context=default
dfs.client.datanode-restart.timeout=30
dfs.client.deadnode.detection.enabled=false
dfs.client.deadnode.detection.idle.sleep.ms=10000
dfs.client.deadnode.detection.probe.connection.timeout.ms=20000
dfs.client.deadnode.detection.probe.deadnode.interval.ms=60000
dfs.client.deadnode.detection.probe.deadnode.threads=10
dfs.client.deadnode.detection.probe.suspectnode.interval.ms=300
dfs.client.deadnode.detection.probe.suspectnode.threads=10
dfs.client.deadnode.detection.rpc.threads=20
dfs.client.domain.socket.data.traffic=false
dfs.client.failover.connection.retries=0
dfs.client.failover.connection.retries.on.timeouts=0
dfs.client.failover.max.attempts=15
dfs.client.failover.proxy.provider.ha-cluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
dfs.client.failover.random.order=false
dfs.client.failover.resolve-needed=false
dfs.client.failover.resolver.impl=org.apache.hadoop.net.DNSDomainNameResolver
dfs.client.failover.resolver.useFQDN=true
dfs.client.failover.sleep.base.millis=500
dfs.client.failover.sleep.max.millis=15000
dfs.client.hedged.read.threadpool.size=0
dfs.client.hedged.read.threshold.millis=500
dfs.client.https.keystore.resource=ssl-client.xml
dfs.client.https.need-auth=false
dfs.client.key.provider.cache.expiry=864000000
dfs.client.max.block.acquire.failures=3
dfs.client.mmap.cache.size=256
dfs.client.mmap.cache.timeout.ms=3600000
dfs.client.mmap.enabled=true
dfs.client.mmap.retry.timeout.ms=300000
dfs.client.read.short.circuit.replica.stale.threshold.ms=1800000
dfs.client.read.shortcircuit=false
dfs.client.read.shortcircuit.buffer.size=1048576
dfs.client.read.shortcircuit.skip.checksum=false
dfs.client.read.shortcircuit.streams.cache.expiry.ms=300000
dfs.client.read.shortcircuit.streams.cache.size=256
dfs.client.read.striped.threadpool.size=18
dfs.client.read.uri.cache.enabled=false
dfs.client.read.use.cache.priority=false
dfs.client.refresh.read-block-locations.ms=0
dfs.client.retry.interval-ms.get-last-block-length=4000
dfs.client.retry.max.attempts=10
dfs.client.retry.policy.enabled=false
dfs.client.retry.policy.spec=10000,6,60000,10
dfs.client.retry.times.get-last-block-length=3
dfs.client.retry.window.base=3000
dfs.client.server-defaults.validity.period.ms=3600000
dfs.client.short.circuit.num=1
dfs.client.short.circuit.replica.stale.threshold.ms=1800000
dfs.client.slow.io.warning.threshold.ms=30000
dfs.client.socket-timeout=60000
dfs.client.socket.send.buffer.size=0
dfs.client.socketcache.capacity=16
dfs.client.socketcache.expiryMsec=3000
dfs.client.test.drop.namenode.response.number=0
dfs.client.use.datanode.hostname=false
dfs.client.use.legacy.blockreader.local=false
dfs.client.write.byte-array-manager.count-limit=2048
dfs.client.write.byte-array-manager.count-reset-time-period-ms=10000
dfs.client.write.byte-array-manager.count-threshold=128
dfs.client.write.byte-array-manager.enabled=false
dfs.client.write.exclude.nodes.cache.expiry.interval.millis=600000
dfs.client.write.max-packets-in-flight=80
dfs.content-summary.limit=5000
dfs.content-summary.sleep-microsec=500
dfs.data.transfer.client.tcpnodelay=true
dfs.data.transfer.server.tcpnodelay=true
dfs.datanode.address=0.0.0.0:9866
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction=0.75f
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold=10737418240
dfs.datanode.balance.bandwidthPerSec=100m
dfs.datanode.balance.max.concurrent.moves=100
dfs.datanode.block-pinning.enabled=false
dfs.datanode.block.id.layout.upgrade.threads=6
dfs.datanode.bp-ready.timeout=20
dfs.datanode.cache.revocation.polling.ms=500
dfs.datanode.cache.revocation.timeout.ms=900000
dfs.datanode.cached-dfsused.check.interval.ms=600000
dfs.datanode.data.dir=/datos/datanode
dfs.datanode.data.dir.perm=700
dfs.datanode.data.transfer.bandwidthPerSec=0
dfs.datanode.data.write.bandwidthPerSec=0
dfs.datanode.directoryscan.interval=21600
dfs.datanode.directoryscan.threads=1
dfs.datanode.directoryscan.throttle.limit.ms.per.sec=1000
dfs.datanode.disk.check.min.gap=15m
dfs.datanode.disk.check.timeout=10m
dfs.datanode.dns.interface=default
dfs.datanode.dns.nameserver=default
dfs.datanode.drop.cache.behind.reads=false
dfs.datanode.drop.cache.behind.writes=false
dfs.datanode.du.reserved=0
dfs.datanode.du.reserved.calculator=org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorAbsolute
dfs.datanode.du.reserved.pct=0
dfs.datanode.ec.reconstruction.stripedread.buffer.size=65536
dfs.datanode.ec.reconstruction.stripedread.timeout.millis=5000
dfs.datanode.ec.reconstruction.threads=8
dfs.datanode.ec.reconstruction.validation=false
dfs.datanode.ec.reconstruction.xmits.weight=0.5
dfs.datanode.failed.volumes.tolerated=0
dfs.datanode.fileio.profiling.sampling.percentage=0
dfs.datanode.fixed.volume.size=false
dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume=4
dfs.datanode.fsdatasetcache.max.threads.per.volume=4
dfs.datanode.handler.count=10
dfs.datanode.http.address=0.0.0.0:9864
dfs.datanode.http.internal-proxy.port=0
dfs.datanode.https.address=0.0.0.0:9865
dfs.datanode.httpserver.filter.handlers=org.apache.hadoop.hdfs.server.datanode.web.RestCsrfPreventionFilterHandler
dfs.datanode.ipc.address=0.0.0.0:9867
dfs.datanode.lazywriter.interval.sec=60
dfs.datanode.lock-reporting-threshold-ms=300
dfs.datanode.lock.fair=true
dfs.datanode.lock.read.write.enabled=true
dfs.datanode.max.locked.memory=0
dfs.datanode.max.transfer.threads=4096
dfs.datanode.metrics.logger.period.seconds=600
dfs.datanode.min.outlier.detection.disks=5
dfs.datanode.network.counts.cache.max.size=2147483647
dfs.datanode.oob.timeout-ms=1500,0,0,0
dfs.datanode.outliers.report.interval=30m
dfs.datanode.peer.metrics.min.outlier.detection.samples=1000
dfs.datanode.peer.stats.enabled=false
dfs.datanode.pmem.cache.recovery=true
dfs.datanode.processcommands.threshold=2s
dfs.datanode.readahead.bytes=4194304
dfs.datanode.replica.cache.expiry.time=5m
dfs.datanode.restart.replica.expiration=50
dfs.datanode.scan.period.hours=504
dfs.datanode.shared.file.descriptor.paths=/dev/shm,/tmp
dfs.datanode.slow.io.warning.threshold.ms=300
dfs.datanode.slowdisk.low.threshold.ms=20
dfs.datanode.socket.reuse.keepalive=4000
dfs.datanode.socket.write.timeout=480000
dfs.datanode.sync.behind.writes=false
dfs.datanode.sync.behind.writes.in.background=false
dfs.datanode.transfer.socket.recv.buffer.size=0
dfs.datanode.transfer.socket.send.buffer.size=0
dfs.datanode.transferTo.allowed=true
dfs.datanode.use.datanode.hostname=false
dfs.default.chunk.view.size=32768
dfs.disk.balancer.block.tolerance.percent=10
dfs.disk.balancer.enabled=true
dfs.disk.balancer.max.disk.errors=5
dfs.disk.balancer.max.disk.throughputInMBperSec=10
dfs.disk.balancer.plan.threshold.percent=10
dfs.disk.balancer.plan.valid.interval=1d
dfs.domain.socket.disable.interval.seconds=600
dfs.edit.log.transfer.bandwidthPerSec=0
dfs.edit.log.transfer.timeout=30000
dfs.encrypt.data.overwrite.downstream.derived.qop=false
dfs.encrypt.data.transfer=false
dfs.encrypt.data.transfer.cipher.key.bitlength=128
dfs.federation.router.admin-address=0.0.0.0:8111
dfs.federation.router.admin.enable=true
dfs.federation.router.admin.handler.count=1
dfs.federation.router.cache.ttl=1m
dfs.federation.router.client.allow-partial-listing=true
dfs.federation.router.client.mount-status.time-out=1s
dfs.federation.router.client.reject.overload=false
dfs.federation.router.client.retry.max.attempts=3
dfs.federation.router.client.thread-size=32
dfs.federation.router.connect.max.retries.on.timeouts=0
dfs.federation.router.connect.timeout=2s
dfs.federation.router.connection.clean.ms=10000
dfs.federation.router.connection.creator.queue-size=100
dfs.federation.router.connection.min-active-ratio=0.5f
dfs.federation.router.connection.pool-size=1
dfs.federation.router.connection.pool.clean.ms=60000
dfs.federation.router.default.nameservice.enable=true
dfs.federation.router.dn-report.cache-expire=10s
dfs.federation.router.dn-report.time-out=1000
dfs.federation.router.file.resolver.client.class=org.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver
dfs.federation.router.handler.count=10
dfs.federation.router.handler.queue.size=100
dfs.federation.router.heartbeat-state.interval=5s
dfs.federation.router.heartbeat.enable=true
dfs.federation.router.heartbeat.interval=5000
dfs.federation.router.http-address=0.0.0.0:50071
dfs.federation.router.http.enable=true
dfs.federation.router.https-address=0.0.0.0:50072
dfs.federation.router.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}
dfs.federation.router.metrics.class=org.apache.hadoop.hdfs.server.federation.metrics.FederationRPCPerformanceMonitor
dfs.federation.router.metrics.enable=true
dfs.federation.router.monitor.localnamenode.enable=true
dfs.federation.router.mount-table.cache.enable=true
dfs.federation.router.mount-table.cache.update=false
dfs.federation.router.mount-table.cache.update.client.max.time=5m
dfs.federation.router.mount-table.cache.update.timeout=1m
dfs.federation.router.mount-table.max-cache-size=10000
dfs.federation.router.namenode.resolver.client.class=org.apache.hadoop.hdfs.server.federation.resolver.MembershipNamenodeResolver
dfs.federation.router.quota-cache.update.interval=60s
dfs.federation.router.quota.enable=false
dfs.federation.router.reader.count=1
dfs.federation.router.reader.queue.size=100
dfs.federation.router.rpc-address=0.0.0.0:8888
dfs.federation.router.rpc.enable=true
dfs.federation.router.safemode.enable=true
dfs.federation.router.safemode.expiration=3m
dfs.federation.router.safemode.extension=30s
dfs.federation.router.secret.manager.class=org.apache.hadoop.hdfs.server.federation.router.security.token.ZKDelegationTokenSecretManagerImpl
dfs.federation.router.store.connection.test=60000
dfs.federation.router.store.driver.class=org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl
dfs.federation.router.store.enable=true
dfs.federation.router.store.membership.expiration=300000
dfs.federation.router.store.membership.expiration.deletion=-1
dfs.federation.router.store.router.expiration=5m
dfs.federation.router.store.router.expiration.deletion=-1
dfs.federation.router.store.serializer=org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializerPBImpl
dfs.ha.allow.stale.reads=false
dfs.ha.automatic-failover.enabled=true
dfs.ha.fencing.methods=sshfence
dfs.ha.fencing.ssh.private-key-files=/home/ernestosegundo/.ssh/id_rsa
dfs.ha.log-roll.period=120
dfs.ha.namenodes.ha-cluster=lluyllucucha,belen
dfs.ha.nn.not-become-active-in-safemode=false
dfs.ha.standby.checkpoints=true
dfs.ha.tail-edits.in-progress=false
dfs.ha.tail-edits.namenode-retries=3
dfs.ha.tail-edits.period=60
dfs.ha.tail-edits.period.backoff-max=0
dfs.ha.tail-edits.rolledits.timeout=60
dfs.ha.zkfc.nn.http.timeout.ms=20000
dfs.ha.zkfc.port=8019
dfs.heartbeat.interval=3
dfs.http.client.failover.max.attempts=15
dfs.http.client.failover.sleep.base.millis=500
dfs.http.client.failover.sleep.max.millis=15000
dfs.http.client.retry.max.attempts=10
dfs.http.client.retry.policy.enabled=false
dfs.http.client.retry.policy.spec=10000,6,60000,10
dfs.http.policy=HTTP_ONLY
dfs.https.server.keystore.resource=ssl-server.xml
dfs.image.compress=false
dfs.image.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
dfs.image.parallel.inode.threshold=1000000
dfs.image.parallel.load=false
dfs.image.parallel.target.sections=12
dfs.image.parallel.threads=4
dfs.image.transfer-bootstrap-standby.bandwidthPerSec=0
dfs.image.transfer.bandwidthPerSec=52428800
dfs.image.transfer.chunksize=65536
dfs.image.transfer.timeout=60000
dfs.journalnode.edit-cache-size.bytes=1048576
dfs.journalnode.edits.dir=/datos/jn
dfs.journalnode.edits.dir.perm=700
dfs.journalnode.enable.sync=true
dfs.journalnode.http-address=0.0.0.0:8480
dfs.journalnode.https-address=0.0.0.0:8481
dfs.journalnode.rpc-address=0.0.0.0:8485
dfs.journalnode.sync.interval=120000
dfs.lock.suppress.warning.interval=10s
dfs.ls.limit=1000
dfs.mover.address=0.0.0.0:0
dfs.mover.keytab.enabled=false
dfs.mover.max-no-move-interval=60000
dfs.mover.movedWinWidth=5400000
dfs.mover.moverThreads=1000
dfs.mover.retry.max.attempts=10
dfs.namenode.accesstime.precision=3600000
dfs.namenode.acls.enabled=true
dfs.namenode.audit.log.async=false
dfs.namenode.audit.log.async.blocking=true
dfs.namenode.audit.log.async.buffer.size=128
dfs.namenode.audit.log.token.tracking.id=false
dfs.namenode.audit.loggers=default
dfs.namenode.available-space-block-placement-policy.balance-local-node=false
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction=0.6
dfs.namenode.available-space-block-placement-policy.balanced-space-tolerance=5
dfs.namenode.available-space-rack-fault-tolerant-block-placement-policy.balanced-space-preference-fraction=0.6
dfs.namenode.available-space-rack-fault-tolerant-block-placement-policy.balanced-space-tolerance=5
dfs.namenode.avoid.read.slow.datanode=false
dfs.namenode.avoid.read.stale.datanode=false
dfs.namenode.avoid.write.stale.datanode=false
dfs.namenode.backup.address=0.0.0.0:50100
dfs.namenode.backup.http-address=0.0.0.0:50105
dfs.namenode.block-placement-policy.default.prefer-local-node=true
dfs.namenode.block-placement-policy.exclude-slow-nodes.enabled=false
dfs.namenode.block.deletion.increment=1000
dfs.namenode.blockreport.max.lock.hold.time=4
dfs.namenode.blockreport.queue.size=1024
dfs.namenode.blocks.per.postponedblocks.rescan=10000
dfs.namenode.caching.enabled=true
dfs.namenode.checkpoint.check.period=60
dfs.namenode.checkpoint.check.quiet-multiplier=1.5
dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary
dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}
dfs.namenode.checkpoint.max-retries=3
dfs.namenode.checkpoint.period=3600
dfs.namenode.checkpoint.txns=1000000
dfs.namenode.corrupt.block.delete.immediately.enabled=true
dfs.namenode.datanode.registration.ip-hostname-check=true
dfs.namenode.decommission.backoff.monitor.pending.blocks.per.lock=1000
dfs.namenode.decommission.backoff.monitor.pending.limit=10000
dfs.namenode.decommission.blocks.per.interval=500000
dfs.namenode.decommission.interval=30
dfs.namenode.decommission.max.concurrent.tracked.nodes=100
dfs.namenode.decommission.monitor.class=org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor
dfs.namenode.delegation.key.update-interval=86400000
dfs.namenode.delegation.token.always-use=false
dfs.namenode.delegation.token.max-lifetime=604800000
dfs.namenode.delegation.token.renew-interval=86400000
dfs.namenode.ec.policies.max.cellsize=4194304
dfs.namenode.ec.system.default.policy=RS-6-3-1024k
dfs.namenode.ec.userdefined.policy.allowed=true
dfs.namenode.edekcacheloader.initial.delay.ms=3000
dfs.namenode.edekcacheloader.interval.ms=1000
dfs.namenode.edit.log.autoroll.check.interval.ms=300000
dfs.namenode.edit.log.autoroll.multiplier.threshold=0.5
dfs.namenode.edits.asynclogging=true
dfs.namenode.edits.dir=${dfs.namenode.name.dir}
dfs.namenode.edits.dir.minimum=1
dfs.namenode.edits.journal-plugin.qjournal=org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
dfs.namenode.edits.noeditlogchannelflush=false
dfs.namenode.enable.log.stale.datanode=false
dfs.namenode.enable.retrycache=true
dfs.namenode.file.close.num-committed-allowed=0
dfs.namenode.fs-limits.max-blocks-per-file=10000
dfs.namenode.fs-limits.max-component-length=255
dfs.namenode.fs-limits.max-directory-items=1048576
dfs.namenode.fs-limits.max-xattr-size=16384
dfs.namenode.fs-limits.max-xattrs-per-inode=32
dfs.namenode.fs-limits.min-block-size=1048576
dfs.namenode.fslock.fair=true
dfs.namenode.full.block.report.lease.length.ms=300000
dfs.namenode.gc.time.monitor.enable=true
dfs.namenode.gc.time.monitor.observation.window.ms=1m
dfs.namenode.gc.time.monitor.sleep.interval.ms=5s
dfs.namenode.get-blocks.max-qps=20
dfs.namenode.handler.count=10
dfs.namenode.heartbeat.recheck-interval=300000
dfs.namenode.hosts.provider.classname=org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager
dfs.namenode.http-address=0.0.0.0:9870
dfs.namenode.http-address.ha-cluster.belen=belen:9870
dfs.namenode.http-address.ha-cluster.lluyllucucha=lluyllucucha:9870
dfs.namenode.https-address=0.0.0.0:9871
dfs.namenode.inotify.max.events.per.rpc=1000
dfs.namenode.invalidate.work.pct.per.iteration=0.32f
dfs.namenode.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}
dfs.namenode.kerberos.principal.pattern=*
dfs.namenode.lazypersist.file.scrub.interval.sec=300
dfs.namenode.lease-hard-limit-sec=1200
dfs.namenode.lease-recheck-interval-ms=2000
dfs.namenode.lifeline.handler.ratio=0.10
dfs.namenode.list.cache.directives.num.responses=100
dfs.namenode.list.cache.pools.num.responses=100
dfs.namenode.list.encryption.zones.num.responses=100
dfs.namenode.list.openfiles.num.responses=1000
dfs.namenode.list.reencryption.status.num.responses=100
dfs.namenode.lock.detailed-metrics.enabled=false
dfs.namenode.maintenance.replication.min=1
dfs.namenode.max-corrupt-file-blocks-returned=100
dfs.namenode.max-lock-hold-to-release-lease-ms=25
dfs.namenode.max-num-blocks-to-log=1000
dfs.namenode.max.extra.edits.segments.retained=10000
dfs.namenode.max.full.block.report.leases=6
dfs.namenode.max.objects=0
dfs.namenode.max.op.size=52428800
dfs.namenode.max.slowpeer.collect.nodes=5
dfs.namenode.metrics.logger.period.seconds=600
dfs.namenode.missing.checkpoint.periods.before.shutdown=3
dfs.namenode.name.cache.threshold=10
dfs.namenode.name.dir=/datos/namenode
dfs.namenode.name.dir.restore=false
dfs.namenode.num.checkpoints.retained=2
dfs.namenode.num.extra.edits.retained=1000000
dfs.namenode.path.based.cache.block.map.allocation.percent=0.25
dfs.namenode.path.based.cache.refresh.interval.ms=30000
dfs.namenode.path.based.cache.retry.interval.ms=30000
dfs.namenode.posix.acl.inheritance.enabled=true
dfs.namenode.provided.enabled=false
dfs.namenode.quota.init-threads=12
dfs.namenode.read-lock-reporting-threshold-ms=5000
dfs.namenode.read.considerLoad=false
dfs.namenode.read.considerStorageType=false
dfs.namenode.reconstruction.pending.timeout-sec=300
dfs.namenode.redundancy.considerLoad=true
dfs.namenode.redundancy.considerLoad.factor=2.0
dfs.namenode.redundancy.considerLoadByStorageType=false
dfs.namenode.redundancy.interval.seconds=3
dfs.namenode.redundancy.queue.restart.iterations=2400
dfs.namenode.reencrypt.batch.size=1000
dfs.namenode.reencrypt.edek.threads=10
dfs.namenode.reencrypt.sleep.interval=1m
dfs.namenode.reencrypt.throttle.limit.handler.ratio=1.0
dfs.namenode.reencrypt.throttle.limit.updater.ratio=1.0
dfs.namenode.reject-unresolved-dn-topology-mapping=false
dfs.namenode.replication.max-streams=2
dfs.namenode.replication.max-streams-hard-limit=4
dfs.namenode.replication.min=1
dfs.namenode.replication.work.multiplier.per.iteration=2
dfs.namenode.resource.check.interval=5000
dfs.namenode.resource.checked.volumes.minimum=1
dfs.namenode.resource.du.reserved=104857600
dfs.namenode.retrycache.expirytime.millis=600000
dfs.namenode.retrycache.heap.percent=0.03f
dfs.namenode.rpc-address.ha-cluster.belen=belen:9000
dfs.namenode.rpc-address.ha-cluster.lluyllucucha=lluyllucucha:9000
dfs.namenode.safemode.extension=30000
dfs.namenode.safemode.min.datanodes=0
dfs.namenode.safemode.threshold-pct=0.999f
dfs.namenode.secondary.http-address=0.0.0.0:9868
dfs.namenode.secondary.https-address=0.0.0.0:9869
dfs.namenode.send.qop.enabled=false
dfs.namenode.service.handler.count=10
dfs.namenode.shared.edits.dir=qjournal://calvario:8485;belen:8485;lluyllucucha:8485/ha-cluster
dfs.namenode.slowpeer.collect.interval=30m
dfs.namenode.snapshot.capture.openfiles=false
dfs.namenode.snapshot.max.limit=65536
dfs.namenode.snapshot.skip.capture.accesstime-only-change=false
dfs.namenode.snapshot.skiplist.interval=10
dfs.namenode.snapshot.skiplist.max.levels=0
dfs.namenode.snapshotdiff.allow.snap-root-descendant=true
dfs.namenode.snapshotdiff.listing.limit=1000
dfs.namenode.stale.datanode.interval=30000
dfs.namenode.stale.datanode.minimum.interval=3
dfs.namenode.startup.delay.block.deletion.sec=0
dfs.namenode.state.context.enabled=false
dfs.namenode.storage.dir.perm=700
dfs.namenode.support.allow.format=true
dfs.namenode.top.enabled=true
dfs.namenode.top.num.users=10
dfs.namenode.top.window.num.buckets=10
dfs.namenode.top.windows.minutes=1,5,25
dfs.namenode.upgrade.domain.factor=${dfs.replication}
dfs.namenode.write-lock-reporting-threshold-ms=5000
dfs.namenode.write.stale.datanode.ratio=0.5f
dfs.namenode.xattrs.enabled=true
dfs.nameservices=ha-cluster
dfs.net.topology.impl=org.apache.hadoop.hdfs.net.DFSNetworkTopology
dfs.permissions.ContentSummary.subAccess=false
dfs.permissions.allow.owner.set.quota=false
dfs.permissions.enabled=false
dfs.permissions.superusergroup=supergroup
dfs.pipeline.ecn=false
dfs.protected.subdirectories.enable=false
dfs.provided.acls.import.enabled=false
dfs.provided.aliasmap.class=org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap
dfs.provided.aliasmap.inmemory.batch-size=500
dfs.provided.aliasmap.inmemory.enabled=false
dfs.provided.aliasmap.inmemory.leveldb.dir=/tmp
dfs.provided.aliasmap.inmemory.server.log=false
dfs.provided.aliasmap.load.retries=0
dfs.provided.aliasmap.text.delimiter=,
dfs.provided.storage.id=DS-PROVIDED
dfs.qjm.operations.timeout=60s
dfs.qjournal.accept-recovery.timeout.ms=120000
dfs.qjournal.finalize-segment.timeout.ms=120000
dfs.qjournal.get-journal-state.timeout.ms=120000
dfs.qjournal.http.open.timeout.ms=60000
dfs.qjournal.http.read.timeout.ms=60000
dfs.qjournal.new-epoch.timeout.ms=120000
dfs.qjournal.parallel-read.num-threads=5
dfs.qjournal.prepare-recovery.timeout.ms=120000
dfs.qjournal.queued-edits.limit.mb=10
dfs.qjournal.select-input-streams.timeout.ms=20000
dfs.qjournal.start-segment.timeout.ms=20000
dfs.qjournal.write-txns.timeout.ms=20000
dfs.quota.by.storage.type.enabled=true
dfs.reformat.disabled=false
dfs.replication=3
dfs.replication.max=512
dfs.secondary.namenode.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms=60000
dfs.storage.policy.enabled=true
dfs.storage.policy.permissions.superuser-only=false
dfs.storage.policy.satisfier.address=0.0.0.0:0
dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms=300000
dfs.storage.policy.satisfier.max.outstanding.paths=10000
dfs.storage.policy.satisfier.mode=none
dfs.storage.policy.satisfier.queue.limit=1000
dfs.storage.policy.satisfier.recheck.timeout.millis=60000
dfs.storage.policy.satisfier.retry.max.attempts=3
dfs.storage.policy.satisfier.self.retry.timeout.millis=300000
dfs.storage.policy.satisfier.work.multiplier.per.iteration=1
dfs.stream-buffer-size=4096
dfs.use.dfs.network.topology=true
dfs.user.home.dir.prefix=/user
dfs.webhdfs.acl.provider.permission.pattern=^(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?(,(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?)*$
dfs.webhdfs.enabled=true
dfs.webhdfs.netty.high.watermark=65535
dfs.webhdfs.netty.low.watermark=32768
dfs.webhdfs.oauth2.enabled=false
dfs.webhdfs.rest-csrf.browser-useragents-regex=^Mozilla.*,^Opera.*
dfs.webhdfs.rest-csrf.custom-header=X-XSRF-HEADER
dfs.webhdfs.rest-csrf.enabled=false
dfs.webhdfs.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD,TRACE
dfs.webhdfs.socket.connect-timeout=60s
dfs.webhdfs.socket.read-timeout=60s
dfs.webhdfs.ugi.expire.after.access=600000
dfs.webhdfs.use.ipc.callq=true
dfs.webhdfs.user.provider.user.pattern=^[A-Za-z_][A-Za-z0-9._-]*[$]?$
dfs.xframe.enabled=true
dfs.xframe.value=SAMEORIGIN
fs.har.impl=org.apache.hadoop.hive.shims.HiveHarFileSystem
ha.zookeeper.quorum=lluyllucucha:2181,belen:2181,calvario:2181
hadoop.bin.path=/opt/hadoop/bin/hadoop
hadoop.fuse.connection.timeout=300
hadoop.fuse.timer.period=5
hadoop.hdfs.configuration.version=1
hadoop.proxyuser.server.groups=*
hadoop.proxyuser.server.hosts=*
hive.allow.udf.load.on.demand=false
hive.analyze.stmt.collect.partlevel.stats=true
hive.archive.enabled=false
hive.arrow.batch.size=1000
hive.arrow.root.allocator.limit=9223372036854775807
hive.async.log.enabled=true
hive.ats.hook.queue.capacity=64
hive.auto.convert.join=true
hive.auto.convert.join.hashtable.max.entries=21000000
hive.auto.convert.join.noconditionaltask=true
hive.auto.convert.join.noconditionaltask.size=10000000
hive.auto.convert.join.shuffle.max.size=10000000000
hive.auto.convert.join.use.nonstaged=false
hive.auto.convert.sortmerge.join=true
hive.auto.convert.sortmerge.join.bigtable.selection.policy=org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
hive.auto.convert.sortmerge.join.reduce.side=true
hive.auto.convert.sortmerge.join.to.mapjoin=false
hive.auto.progress.timeout=0s
hive.autogen.columnalias.prefix.includefuncname=false
hive.autogen.columnalias.prefix.label=_c
hive.avro.timestamp.skip.conversion=false
hive.binary.record.max.length=1000
hive.blobstore.optimizations.enabled=true
hive.blobstore.supported.schemes=s3,s3a,s3n
hive.blobstore.use.blobstore.as.scratchdir=false
hive.cache.expr.evaluation=true
hive.cbo.cnf.maxnodes=-1
hive.cbo.costmodel.cpu=0.000001
hive.cbo.costmodel.extended=false
hive.cbo.costmodel.hdfs.read=1.5
hive.cbo.costmodel.hdfs.write=10.0
hive.cbo.costmodel.local.fs.read=4.0
hive.cbo.costmodel.local.fs.write=4.0
hive.cbo.costmodel.network=150.0
hive.cbo.enable=true
hive.cbo.returnpath.hiveop=false
hive.cbo.show.warnings=true
hive.cli.errors.ignore=false
hive.cli.pretty.output.num.cols=-1
hive.cli.print.current.db=false
hive.cli.print.escape.crlf=false
hive.cli.print.header=false
hive.cli.prompt=hive
hive.cli.tez.session.async=true
hive.cluster.delegation.token.store.class=org.apache.hadoop.hive.thrift.MemoryTokenStore
hive.cluster.delegation.token.store.zookeeper.znode=/hivedelegation
hive.combine.equivalent.work.optimization=true
hive.compactor.abortedtxn.threshold=1000
hive.compactor.check.interval=300s
hive.compactor.cleaner.run.interval=5000ms
hive.compactor.compact.insert.only=true
hive.compactor.delta.num.threshold=10
hive.compactor.delta.pct.threshold=0.1
hive.compactor.history.reaper.interval=2m
hive.compactor.history.retention.attempted=2
hive.compactor.history.retention.failed=3
hive.compactor.history.retention.succeeded=3
hive.compactor.initiator.failed.compacts.threshold=2
hive.compactor.initiator.on=false
hive.compactor.max.num.delta=500
hive.compactor.worker.threads=0
hive.compactor.worker.timeout=86400s
hive.compat=0.12
hive.compute.query.using.stats=true
hive.compute.splits.in.am=true
hive.conf.hidden.list=javax.jdo.option.ConnectionPassword,hive.server2.keystore.password,fs.s3.awsAccessKeyId,fs.s3.awsSecretAccessKey,fs.s3n.awsAccessKeyId,fs.s3n.awsSecretAccessKey,fs.s3a.access.key,fs.s3a.secret.key,fs.s3a.proxy.password,dfs.adls.oauth2.credential,fs.adl.oauth2.credential
hive.conf.internal.variable.list=hive.added.files.path,hive.added.jars.path,hive.added.archives.path
hive.conf.restricted.list=hive.security.authenticator.manager,hive.security.authorization.manager,hive.security.metastore.authorization.manager,hive.security.metastore.authenticator.manager,hive.users.in.admin.role,hive.server2.xsrf.filter.enabled,hive.security.authorization.enabled,hive.distcp.privileged.doAs,hive.server2.authentication.ldap.baseDN,hive.server2.authentication.ldap.url,hive.server2.authentication.ldap.Domain,hive.server2.authentication.ldap.groupDNPattern,hive.server2.authentication.ldap.groupFilter,hive.server2.authentication.ldap.userDNPattern,hive.server2.authentication.ldap.userFilter,hive.server2.authentication.ldap.groupMembershipKey,hive.server2.authentication.ldap.userMembershipKey,hive.server2.authentication.ldap.groupClassKey,hive.server2.authentication.ldap.customLDAPQuery,hive.privilege.synchronizer,hive.privilege.synchronizer.interval,hive.spark.client.connect.timeout,hive.spark.client.server.connect.timeout,hive.spark.client.channel.log.level,hive.spark.client.rpc.max.size,hive.spark.client.rpc.threads,hive.spark.client.secret.bits,hive.spark.client.rpc.server.address,hive.spark.client.rpc.server.port,hive.spark.client.rpc.sasl.mechanisms,bonecp.,hive.druid.broker.address.default,hive.druid.coordinator.address.default,hikari.,hadoop.bin.path,yarn.bin.path,spark.home,_hive.local.session.path,_hive.hdfs.session.path,_hive.tmp_table_space
hive.conf.validation=true
hive.constraint.notnull.enforce=true
hive.convert.join.bucket.mapjoin.tez=true
hive.count.open.txns.interval=1s
hive.counters.group.name=HIVE
hive.create.as.insert.only=false
hive.debug.localtask=false
hive.decode.partition.name=false
hive.default.fileformat=TextFile
hive.default.fileformat.managed=none
hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe
hive.default.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.describe.partitionedtable.ignore.stats=false
hive.direct.sql.max.elements.in.clause=1000
hive.direct.sql.max.elements.values.clause=1000
hive.direct.sql.max.query.length=100
hive.disable.unsafe.external.table.operations=true
hive.display.partition.cols.separately=true
hive.distcp.privileged.doAs=hive
hive.downloaded.resources.dir=${system:java.io.tmpdir}/${hive.session.id}_resources
hive.driver.parallel.compilation=false
hive.druid.bitmap.type=roaring
hive.druid.broker.address.default=localhost:8082
hive.druid.coordinator.address.default=localhost:8081
hive.druid.http.numConnection=20
hive.druid.http.read.timeout=PT1M
hive.druid.indexer.memory.rownum.max=75000
hive.druid.indexer.partition.size.max=5000000
hive.druid.indexer.segments.granularity=DAY
hive.druid.maxTries=5
hive.druid.metadata.base=druid
hive.druid.metadata.db.type=mysql
hive.druid.overlord.address.default=localhost:8090
hive.druid.passiveWaitTimeMs=30000
hive.druid.select.threshold=10000
hive.druid.sleep.time=PT10S
hive.druid.storage.storageDirectory=/druid/segments
hive.druid.working.directory=/tmp/workingDirectory
hive.enforce.bucketmapjoin=false
hive.enforce.sortmergebucketmapjoin=false
hive.entity.capture.transform=false
hive.entity.separator=@
hive.error.on.empty.partition=false
hive.exec.check.crossproducts=true
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
hive.exec.copyfile.maxnumfiles=1
hive.exec.copyfile.maxsize=33554432
hive.exec.counters.pull.interval=1000
hive.exec.default.partition.name=__HIVE_DEFAULT_PARTITION__
hive.exec.drop.ignorenonexistent=true
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=strict
hive.exec.infer.bucket.sort=false
hive.exec.infer.bucket.sort.num.buckets.power.two=false
hive.exec.input.listing.max.threads=0
hive.exec.job.debug.capture.stacktraces=true
hive.exec.job.debug.timeout=30000
hive.exec.local.scratchdir=${system:java.io.tmpdir}/${system:user.name}
hive.exec.max.created.files=100000
hive.exec.max.dynamic.partitions=1000
hive.exec.max.dynamic.partitions.pernode=100
hive.exec.mode.local.auto=false
hive.exec.mode.local.auto.input.files.max=4
hive.exec.mode.local.auto.inputbytes.max=134217728
hive.exec.orc.base.delta.ratio=8
hive.exec.orc.delta.streaming.optimizations.enabled=false
hive.exec.orc.split.strategy=HYBRID
hive.exec.parallel=false
hive.exec.parallel.thread.number=8
hive.exec.perf.logger=org.apache.hadoop.hive.ql.log.PerfLogger
hive.exec.rcfile.use.explicit.header=true
hive.exec.rcfile.use.sync.cache=true
hive.exec.reducers.bytes.per.reducer=256000000
hive.exec.reducers.max=1009
hive.exec.rowoffset=false
hive.exec.schema.evolution=true
hive.exec.scratchdir=/tmp/hive
hive.exec.script.allow.partial.consumption=false
hive.exec.script.maxerrsize=100000
hive.exec.script.trust=false
hive.exec.show.job.failure.debug.info=true
hive.exec.stagingdir=.hive-staging
hive.exec.submit.local.task.via.child=true
hive.exec.submitviachild=false
hive.exec.tasklog.debug.timeout=20000
hive.exec.temporary.table.storage=default
hive.execution.engine=mr
hive.execution.mode=container
hive.exim.strict.repl.tables=true
hive.exim.test.mode=false
hive.exim.uri.scheme.whitelist=hdfs,pfile,file,s3,s3a
hive.explain.dependency.append.tasktype=false
hive.explain.user=true
hive.fetch.output.serde=org.apache.hadoop.hive.serde2.DelimitedJSONSerDe
hive.fetch.task.aggr=false
hive.fetch.task.conversion=more
hive.fetch.task.conversion.threshold=1073741824
hive.file.max.footer=100
hive.fileformat.check=true
hive.groupby.limit.extrastep=true
hive.groupby.mapaggr.checkinterval=100000
hive.groupby.orderby.position.alias=false
hive.groupby.position.alias=false
hive.groupby.skewindata=false
hive.hash.table.inflation.factor=2.0
hive.hashtable.initialCapacity=100000
hive.hashtable.key.count.adjustment=2.0
hive.hashtable.loadfactor=0.75
hive.hbase.generatehfiles=false
hive.hbase.snapshot.restoredir=/tmp
hive.hbase.wal.enabled=true
hive.heap.memory.monitor.usage.threshold=0.7
hive.heartbeat.interval=1000
hive.hmshandler.force.reload.conf=false
hive.hmshandler.retry.attempts=10
hive.hmshandler.retry.interval=2000ms
hive.ignore.mapjoin.hint=true
hive.in.ide.test=false
hive.in.repl.test=false
hive.in.ssl.test=false
hive.in.test=false
hive.in.tez.test=false
hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
hive.insert.into.external.tables=true
hive.insert.into.multilevel.dirs=false
hive.int.timestamp.conversion.in.seconds=false
hive.io.rcfile.column.number.conf=0
hive.io.rcfile.record.buffer.size=4194304
hive.io.rcfile.record.interval=2147483647
hive.io.rcfile.tolerate.corruptions=false
hive.io.sarg.cache.max.weight.mb=10
hive.jobname.length=50
hive.join.cache.size=25000
hive.join.emit.interval=1000
hive.join.inner.residual=false
hive.lazysimple.extended_boolean_literal=false
hive.legacy.schema.for.all.serdes=false
hive.limit.optimize.enable=false
hive.limit.optimize.fetch.max=50000
hive.limit.optimize.limit.file=10
hive.limit.pushdown.memory.usage=0.1
hive.limit.row.max.size=100000
hive.llap.allow.permanent.fns=true
hive.llap.am.liveness.connection.sleep.between.retries.ms=2000ms
hive.llap.am.liveness.connection.timeout.ms=10000ms
hive.llap.am.use.fqdn=true
hive.llap.auto.allow.uber=false
hive.llap.auto.auth=false
hive.llap.auto.enforce.stats=true
hive.llap.auto.enforce.tree=true
hive.llap.auto.enforce.vectorized=true
hive.llap.auto.max.input.size=10737418240
hive.llap.auto.max.output.size=1073741824
hive.llap.cache.allow.synthetic.fileid=true
hive.llap.cache.defaultfs.only.native.fileid=true
hive.llap.client.consistent.splits=true
hive.llap.daemon.acl=*
hive.llap.daemon.am-reporter.max.threads=4
hive.llap.daemon.am.liveness.heartbeat.interval.ms=10000ms
hive.llap.daemon.communicator.num.threads=10
hive.llap.daemon.delegation.token.lifetime=14d
hive.llap.daemon.download.permanent.fns=false
hive.llap.daemon.logger=query-routing
hive.llap.daemon.memory.per.instance.mb=4096
hive.llap.daemon.num.executors=4
hive.llap.daemon.num.file.cleaner.threads=1
hive.llap.daemon.output.service.max.pending.writes=8
hive.llap.daemon.output.service.port=15003
hive.llap.daemon.output.service.send.buffer.size=131072
hive.llap.daemon.output.stream.timeout=120s
hive.llap.daemon.rpc.num.handlers=5
hive.llap.daemon.rpc.port=0
hive.llap.daemon.service.refresh.interval.sec=60s
hive.llap.daemon.shuffle.dir.watcher.enabled=false
hive.llap.daemon.task.preemption.metrics.intervals=30,60,300
hive.llap.daemon.task.scheduler.enable.preemption=true
hive.llap.daemon.task.scheduler.wait.queue.size=10
hive.llap.daemon.vcpus.per.instance=4
hive.llap.daemon.wait.queue.comparator.class.name=org.apache.hadoop.hive.llap.daemon.impl.comparator.ShortestJobFirstComparator
hive.llap.daemon.web.port=15002
hive.llap.daemon.web.ssl=false
hive.llap.daemon.xmx.headroom=5%
hive.llap.daemon.yarn.container.mb=-1
hive.llap.daemon.yarn.shuffle.port=15551
hive.llap.enable.grace.join.in.llap=false
hive.llap.execution.mode=none
hive.llap.external.splits.order.by.force.single.split=true
hive.llap.external.splits.temp.table.storage.format=orc
hive.llap.file.cleanup.delay.seconds=300s
hive.llap.hs2.coordinator.enabled=true
hive.llap.io.acid=true
hive.llap.io.allocator.alloc.max=16Mb
hive.llap.io.allocator.alloc.min=4Kb
hive.llap.io.allocator.arena.count=8
hive.llap.io.allocator.defrag.headroom=1Mb
hive.llap.io.allocator.direct=true
hive.llap.io.allocator.discard.method=both
hive.llap.io.allocator.mmap=false
hive.llap.io.allocator.mmap.path=/tmp
hive.llap.io.decoding.metrics.percentiles.intervals=30
hive.llap.io.encode.alloc.size=256Kb
hive.llap.io.encode.enabled=true
hive.llap.io.encode.formats=org.apache.hadoop.mapred.TextInputFormat,
hive.llap.io.encode.slice.lrr=true
hive.llap.io.encode.slice.row.count=100000
hive.llap.io.encode.vector.serde.async.enabled=true
hive.llap.io.encode.vector.serde.enabled=true
hive.llap.io.lrfu.lambda=1.0E-6
hive.llap.io.memory.mode=cache
hive.llap.io.memory.size=1Gb
hive.llap.io.nonvector.wrapper.enabled=true
hive.llap.io.orc.time.counters=true
hive.llap.io.row.wrapper.enabled=true
hive.llap.io.share.object.pools=false
hive.llap.io.threadpool.size=10
hive.llap.io.trace.always.dump=false
hive.llap.io.trace.size=2Mb
hive.llap.io.track.cache.usage=true
hive.llap.io.use.fileid.path=true
hive.llap.io.use.lrfu=true
hive.llap.io.vrb.queue.limit.base=50000
hive.llap.io.vrb.queue.limit.min=10
hive.llap.management.acl=*
hive.llap.management.rpc.port=15004
hive.llap.mapjoin.memory.monitor.check.interval=100000
hive.llap.mapjoin.memory.oversubscribe.factor=0.2
hive.llap.memory.oversubscription.max.executors.per.query=3
hive.llap.object.cache.enabled=true
hive.llap.orc.gap.cache=true
hive.llap.output.format.arrow=true
hive.llap.plugin.acl=*
hive.llap.plugin.client.num.threads=10
hive.llap.plugin.rpc.num.handlers=1
hive.llap.remote.token.requires.signing=true
hive.llap.skip.compile.udf.check=false
hive.llap.task.communicator.connection.sleep.between.retries.ms=2000ms
hive.llap.task.communicator.connection.timeout.ms=16000ms
hive.llap.task.communicator.listener.thread-count=30
hive.llap.task.scheduler.am.registry=llap
hive.llap.task.scheduler.locality.delay=0ms
hive.llap.task.scheduler.node.disable.backoff.factor=1.5
hive.llap.task.scheduler.node.reenable.max.timeout.ms=10000ms
hive.llap.task.scheduler.node.reenable.min.timeout.ms=200ms
hive.llap.task.scheduler.num.schedulable.tasks.per.node=0
hive.llap.task.scheduler.preempt.independent=false
hive.llap.task.scheduler.timeout.seconds=60s
hive.llap.validate.acls=true
hive.llap.zk.sm.session.timeout=40s
hive.load.dynamic.partitions.thread=15
hive.local.time.zone=LOCAL
hive.localize.resource.num.wait.attempts=5
hive.localize.resource.wait.interval=5000ms
hive.lock.manager=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
hive.lock.mapred.only.operation=false
hive.lock.numretries=100
hive.lock.query.string.max.length=1000000
hive.lock.sleep.between.retries=60s
hive.lockmgr.zookeeper.default.partition.name=__HIVE_DEFAULT_ZOOKEEPER_PARTITION__
hive.log.every.n.records=0
hive.log.explain.output=false
hive.map.aggr=true
hive.map.aggr.hash.force.flush.memory.threshold=0.9
hive.map.aggr.hash.min.reduction=0.5
hive.map.aggr.hash.percentmemory=0.5
hive.map.groupby.sorted=true
hive.mapjoin.bucket.cache.size=100
hive.mapjoin.check.memory.rows=100000
hive.mapjoin.followby.gby.localtask.max.memory.usage=0.55
hive.mapjoin.followby.map.aggr.hash.percentmemory=0.3
hive.mapjoin.hybridgrace.bloomfilter=true
hive.mapjoin.hybridgrace.hashtable=true
hive.mapjoin.hybridgrace.memcheckfrequency=1024
hive.mapjoin.hybridgrace.minnumpartitions=16
hive.mapjoin.hybridgrace.minwbsize=524288
hive.mapjoin.localtask.max.memory.usage=0.9
hive.mapjoin.optimized.hashtable=true
hive.mapjoin.optimized.hashtable.probe.percent=0.5
hive.mapjoin.optimized.hashtable.wbsize=8388608
hive.mapjoin.smalltable.filesize=25000000
hive.mapjoin.testing.no.hash.table.load=false
hive.mapper.cannot.span.multiple.partitions=false
hive.mapred.local.mem=0
hive.mapred.partitioner=org.apache.hadoop.hive.ql.io.DefaultHivePartitioner
hive.mapred.reduce.tasks.speculative.execution=true
hive.materializedview.fileformat=ORC
hive.materializedview.rebuild.incremental=true
hive.materializedview.rewriting=true
hive.materializedview.rewriting.incremental=false
hive.materializedview.rewriting.strategy=heuristic
hive.materializedview.rewriting.time.window=0min
hive.materializedview.serde=org.apache.hadoop.hive.ql.io.orc.OrcSerde
hive.max.open.txns=100000
hive.merge.cardinality.check=true
hive.merge.mapfiles=true
hive.merge.mapredfiles=false
hive.merge.nway.joins=true
hive.merge.orcfile.stripe.level=true
hive.merge.rcfile.block.level=true
hive.merge.size.per.task=256000000
hive.merge.smallfiles.avgsize=16000000
hive.merge.sparkfiles=false
hive.merge.tezfiles=false
hive.metadata.move.exported.metadata.to.trash=true
hive.metastore.aggregate.stats.cache.clean.until=0.8
hive.metastore.aggregate.stats.cache.enabled=true
hive.metastore.aggregate.stats.cache.fpp=0.01
hive.metastore.aggregate.stats.cache.max.full=0.9
hive.metastore.aggregate.stats.cache.max.partitions=10000
hive.metastore.aggregate.stats.cache.max.reader.wait=1000ms
hive.metastore.aggregate.stats.cache.max.variance=0.01
hive.metastore.aggregate.stats.cache.max.writer.wait=5000ms
hive.metastore.aggregate.stats.cache.size=10000
hive.metastore.aggregate.stats.cache.ttl=600s
hive.metastore.archive.intermediate.archived=_INTERMEDIATE_ARCHIVED
hive.metastore.archive.intermediate.extracted=_INTERMEDIATE_EXTRACTED
hive.metastore.archive.intermediate.original=_INTERMEDIATE_ORIGINAL
hive.metastore.authorization.storage.check.externaltable.drop=true
hive.metastore.authorization.storage.checks=false
hive.metastore.batch.retrieve.max=300
hive.metastore.batch.retrieve.table.partition.max=1000
hive.metastore.cache.pinobjtypes=Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order
hive.metastore.client.cache.enabled=false
hive.metastore.client.cache.expiry.time=120s
hive.metastore.client.cache.initial.capacity=50
hive.metastore.client.cache.max.capacity=50
hive.metastore.client.cache.stats.enabled=false
hive.metastore.client.capability.check=true
hive.metastore.client.connect.retry.delay=1s
hive.metastore.client.drop.partitions.using.expressions=true
hive.metastore.client.socket.lifetime=0s
hive.metastore.client.socket.timeout=600s
hive.metastore.connect.retries=3
hive.metastore.db.type=DERBY
hive.metastore.direct.sql.batch.size=0
hive.metastore.disallow.incompatible.col.type.changes=true
hive.metastore.dml.events=false
hive.metastore.event.clean.freq=0s
hive.metastore.event.db.listener.timetolive=86400s
hive.metastore.event.db.notification.api.auth=true
hive.metastore.event.expiry.duration=0s
hive.metastore.event.message.factory=org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory
hive.metastore.execute.setugi=true
hive.metastore.expression.proxy=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
hive.metastore.failure.retries=1
hive.metastore.fastpath=false
hive.metastore.filter.hook=org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
hive.metastore.fs.handler.class=org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
hive.metastore.fshandler.threads=15
hive.metastore.hbase.file.metadata.threads=1
hive.metastore.initial.metadata.count.enabled=true
hive.metastore.integral.jdo.pushdown=false
hive.metastore.kerberos.principal=hive-metastore/_HOST@EXAMPLE.COM
hive.metastore.limit.partition.request=-1
hive.metastore.metrics.enabled=false
hive.metastore.orm.retrieveMapNullsAsEmptyStrings=false
hive.metastore.port=9083
hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore
hive.metastore.sasl.enabled=false
hive.metastore.schema.info.class=org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo
hive.metastore.schema.verification=true
hive.metastore.schema.verification.record.version=false
hive.metastore.server.max.message.size=104857600
hive.metastore.server.max.threads=1000
hive.metastore.server.min.threads=200
hive.metastore.server.tcp.keepalive=true
hive.metastore.stats.ndv.densityfunction=false
hive.metastore.stats.ndv.tuner=0.0
hive.metastore.thrift.compact.protocol.enabled=false
hive.metastore.thrift.framed.transport.enabled=false
hive.metastore.try.direct.sql=true
hive.metastore.try.direct.sql.ddl=true
hive.metastore.txn.store.impl=org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
hive.metastore.uri.selection=RANDOM
hive.metastore.use.SSL=false
hive.metastore.warehouse.dir=/user/hive/warehouse
hive.metastore.wm.default.pool.size=4
hive.mm.allow.originals=false
hive.mm.avoid.s3.globstatus=true
hive.msck.path.validation=throw
hive.msck.repair.batch.max.retries=4
hive.msck.repair.batch.size=3000
hive.multi.insert.move.tasks.share.dependencies=false
hive.multigroupby.singlereducer=true
hive.mv.files.thread=15
hive.new.job.grouping.set.cardinality=30
hive.notification.event.consumers=org.apache.hadoop.hive.ql.cache.results.QueryResultsCache$InvalidationEventConsumer
hive.notification.event.poll.interval=60s
hive.notification.sequence.lock.max.retries=5
hive.notification.sequence.lock.retry.sleep.interval=500
hive.optimize.bucketingsorting=true
hive.optimize.bucketmapjoin=false
hive.optimize.bucketmapjoin.sortedmerge=false
hive.optimize.constant.propagation=true
hive.optimize.correlation=false
hive.optimize.countdistinct=true
hive.optimize.cte.materialize.threshold=-1
hive.optimize.distinct.rewrite=true
hive.optimize.dynamic.partition.hashjoin=false
hive.optimize.filter.stats.reduction=false
hive.optimize.groupby=true
hive.optimize.index.filter=false
hive.optimize.joinreducededuplication=true
hive.optimize.limittranspose=false
hive.optimize.limittranspose.reductionpercentage=1.0
hive.optimize.limittranspose.reductiontuples=0
hive.optimize.listbucketing=false
hive.optimize.metadataonly=false
hive.optimize.null.scan=true
hive.optimize.partition.columns.separate=true
hive.optimize.point.lookup=true
hive.optimize.point.lookup.min=31
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.optimize.ppd.windowing=true
hive.optimize.reducededuplication=true
hive.optimize.reducededuplication.min.reducer=4
hive.optimize.remove.identity.project=true
hive.optimize.remove.sq_count_check=false
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
hive.optimize.semijoin.conversion=true
hive.optimize.shared.work=true
hive.optimize.shared.work.extended=true
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.sort.dynamic.partition=false
hive.optimize.union.remove=false
hive.optimize.update.table.properties.from.serde=false
hive.optimize.update.table.properties.from.serde.list=org.apache.hadoop.hive.serde2.avro.AvroSerDe
hive.orc.cache.stripe.details.mem.size=256Mb
hive.orc.cache.use.soft.references=false
hive.orc.compute.splits.num.threads=10
hive.orc.splits.allow.synthetic.fileid=true
hive.orc.splits.directory.batch.ms=0
hive.orc.splits.include.file.footer=false
hive.orc.splits.include.fileid=true
hive.orc.splits.ms.footer.cache.enabled=false
hive.orc.splits.ms.footer.cache.ppd.enabled=true
hive.order.columnalignment=true
hive.orderby.position.alias=true
hive.parquet.timestamp.skip.conversion=false
hive.ppd.recognizetransivity=true
hive.ppd.remove.duplicatefilters=true
hive.prewarm.enabled=false
hive.prewarm.numcontainers=10
hive.prewarm.spark.timeout=5000ms
hive.privilege.synchronizer.interval=1800s
hive.query.reexecution.always.collect.operator.stats=false
hive.query.reexecution.enabled=true
hive.query.reexecution.max.count=1
hive.query.reexecution.stats.cache.batch.size=-1
hive.query.reexecution.stats.cache.size=100000
hive.query.reexecution.stats.persist.scope=query
hive.query.reexecution.strategies=overlay,reoptimize
hive.query.result.fileformat=SequenceFile
hive.query.results.cache.directory=/tmp/hive/_resultscache_
hive.query.results.cache.enabled=true
hive.query.results.cache.max.entry.lifetime=3600s
hive.query.results.cache.max.entry.size=10485760
hive.query.results.cache.max.size=2147483648
hive.query.results.cache.nontransactional.tables.enabled=false
hive.query.results.cache.wait.for.pending.results=true
hive.query.timeout.seconds=0s
hive.querylog.enable.plan.progress=true
hive.querylog.location=${system:java.io.tmpdir}/${system:user.name}
hive.querylog.plan.progress.interval=60000ms
hive.remove.orderby.in.subquery=true
hive.reorder.nway.joins=true
hive.repl.add.raw.reserved.namespace=false
hive.repl.approx.max.load.tasks=10000
hive.repl.bootstrap.dump.open.txn.timeout=1h
hive.repl.cm.enabled=false
hive.repl.cm.interval=3600s
hive.repl.cm.retain=24h
hive.repl.cmrootdir=/user/hive/cmroot/
hive.repl.dump.include.acid.tables=false
hive.repl.dump.metadata.only=false
hive.repl.dumpdir.clean.freq=0s
hive.repl.dumpdir.ttl=7d
hive.repl.partitions.dump.parallelism=100
hive.repl.replica.functions.root.dir=/user/hive/repl/functions/
hive.repl.rootdir=/user/hive/repl/
hive.repl.task.factory=org.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory
hive.resource.use.hdfs.location=true
hive.resultset.use.unique.column.names=true
hive.rework.mapredwork=false
hive.rpc.query.plan=false
hive.sample.seednumber=0
hive.scratch.dir.permission=700
hive.scratchdir.lock=false
hive.script.auto.progress=false
hive.script.operator.env.blacklist=hive.txn.valid.txns,hive.txn.tables.valid.writeids,hive.txn.valid.writeids,hive.script.operator.env.blacklist
hive.script.operator.id.env.var=HIVE_SCRIPT_OPERATOR_ID
hive.script.operator.truncate.env=false
hive.script.recordreader=org.apache.hadoop.hive.ql.exec.TextRecordReader
hive.script.recordwriter=org.apache.hadoop.hive.ql.exec.TextRecordWriter
hive.script.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
hive.security.authorization.enabled=false
hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory
hive.security.authorization.sqlstd.confwhitelist=hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.druid\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.server2\.thrift\.resultset\.default\.fetch\.size|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.strict\..*|hive\.tez\..*|hive\.vectorized\..*|fs\.defaultFS|ssl\.client\.truststore\.location|distcp\.atomic|distcp\.ignore\.failures|distcp\.preserve\.status|distcp\.preserve\.rawxattrs|distcp\.sync\.folders|distcp\.delete\.missing\.source|distcp\.keystore\.resource|distcp\.liststatus\.threads|distcp\.max\.maps|distcp\.copy\.strategy|distcp\.skip\.crc|distcp\.copy\.overwrite|distcp\.copy\.append|distcp\.map\.bandwidth\.mb|distcp\.dynamic\..*|distcp\.meta\.folder|distcp\.copy\.listing\.class|distcp\.filters\.class|distcp\.options\.skipcrccheck|distcp\.options\.m|distcp\.options\.numListstatusThreads|distcp\.options\.mapredSslConf|distcp\.options\.bandwidth|distcp\.options\.overwrite|distcp\.options\.strategy|distcp\.options\.i|distcp\.options\.p.*|distcp\.options\.update|distcp\.options\.delete|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queue\.name|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.transpose\.aggr\.join|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketmapjoin|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.query\.result\.fileformat|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.cli\.tez\.session\.async|hive\.compat|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.query\.results\.cache\.enabled|hive\.query\.results\.cache\.wait\.for\.pending\.results|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.exec\.schema\.evolution|hive\.server2\.logging\.operation\.level|hive\.server2\.thrift\.resultset\.serialize\.in\.tasks|hive\.support\.special\.characters\.tablename|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.llap\.io\.enabled|hive\.llap\.io\.use\.fileid\.path|hive\.llap\.daemon\.service\.hosts|hive\.llap\.execution\.mode|hive\.llap\.auto\.allow\.uber|hive\.llap\.auto\.enforce\.tree|hive\.llap\.auto\.enforce\.vectorized|hive\.llap\.auto\.enforce\.stats|hive\.llap\.auto\.max\.input\.size|hive\.llap\.auto\.max\.output\.size|hive\.llap\.skip\.compile\.udf\.check|hive\.llap\.client\.consistent\.splits|hive\.llap\.enable\.grace\.join\.in\.llap|hive\.llap\.allow\.permanent\.fns|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout|hive\.query\.id
hive.security.authorization.task.factory=org.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl
hive.security.command.whitelist=set,reset,dfs,add,list,delete,reload,compile,llap
hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.security.metastore.authorization.auth.reads=true
hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider
hive.serdes.using.metastore.for.schema=org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
hive.server.read.socket.timeout=10s
hive.server.tcp.keepalive=true
hive.server2.active.passive.ha.enable=false
hive.server2.active.passive.ha.registry.namespace=hs2ActivePassiveHA
hive.server2.allow.user.substitution=true
hive.server2.async.exec.async.compile=false
hive.server2.async.exec.keepalive.time=10s
hive.server2.async.exec.shutdown.timeout=10s
hive.server2.async.exec.threads=100
hive.server2.async.exec.wait.queue.size=100
hive.server2.authentication=NONE
hive.server2.authentication.ldap.groupClassKey=groupOfNames
hive.server2.authentication.ldap.groupMembershipKey=member
hive.server2.authentication.ldap.guidKey=uid
hive.server2.clear.dangling.scratchdir=false
hive.server2.clear.dangling.scratchdir.interval=1800s
hive.server2.close.session.on.disconnect=true
hive.server2.compile.lock.timeout=0s
hive.server2.enable.doAs=false
hive.server2.global.init.file.location=${env:HIVE_CONF_DIR}
hive.server2.idle.operation.timeout=5d
hive.server2.idle.session.check.operation=true
hive.server2.idle.session.timeout=7d
hive.server2.in.place.progress=true
hive.server2.limit.connections.per.ipaddress=0
hive.server2.limit.connections.per.user=0
hive.server2.limit.connections.per.user.ipaddress=0
hive.server2.llap.concurrent.queries=-1
hive.server2.logging.operation.enabled=true
hive.server2.logging.operation.level=EXECUTION
hive.server2.logging.operation.log.location=${system:java.io.tmpdir}/${system:user.name}/operation_logs
hive.server2.long.polling.timeout=5000ms
hive.server2.map.fair.scheduler.queue=true
hive.server2.materializedviews.registry.impl=DEFAULT
hive.server2.max.start.attempts=30
hive.server2.metrics.enabled=false
hive.server2.operation.log.cleanup.delay=300s
hive.server2.parallel.ops.in.session=true
hive.server2.session.check.interval=6h
hive.server2.sleep.interval.between.start.attempts=60s
hive.server2.support.dynamic.service.discovery=false
hive.server2.table.type.mapping=CLASSIC
hive.server2.tez.initialize.default.sessions=false
hive.server2.tez.queue.access.check=false
hive.server2.tez.session.lifetime=162h
hive.server2.tez.session.lifetime.jitter=3h
hive.server2.tez.sessions.custom.queue.allowed=true
hive.server2.tez.sessions.init.threads=16
hive.server2.tez.sessions.per.default.queue=1
hive.server2.tez.wm.am.registry.timeout=30s
hive.server2.thrift.client.connect.retry.limit=1
hive.server2.thrift.client.password=anonymous
hive.server2.thrift.client.retry.delay.seconds=1s
hive.server2.thrift.client.retry.limit=1
hive.server2.thrift.client.user=anonymous
hive.server2.thrift.exponential.backoff.slot.length=100ms
hive.server2.thrift.http.compression.enabled=true
hive.server2.thrift.http.cookie.auth.enabled=true
hive.server2.thrift.http.cookie.is.httponly=true
hive.server2.thrift.http.cookie.is.secure=true
hive.server2.thrift.http.cookie.max.age=86400s
hive.server2.thrift.http.max.idle.time=1800s
hive.server2.thrift.http.path=cliservice
hive.server2.thrift.http.port=10001
hive.server2.thrift.http.request.header.size=6144
hive.server2.thrift.http.response.header.size=6144
hive.server2.thrift.http.worker.keepalive.time=60s
hive.server2.thrift.login.timeout=20s
hive.server2.thrift.max.message.size=104857600
hive.server2.thrift.max.worker.threads=500
hive.server2.thrift.min.worker.threads=5
hive.server2.thrift.port=10000
hive.server2.thrift.resultset.default.fetch.size=1000
hive.server2.thrift.resultset.max.fetch.size=10000
hive.server2.thrift.resultset.serialize.in.tasks=false
hive.server2.thrift.sasl.qop=auth
hive.server2.thrift.worker.keepalive.time=60s
hive.server2.transport.mode=binary
hive.server2.use.SSL=false
hive.server2.webui.cors.allowed.headers=X-Requested-With,Content-Type,Accept,Origin
hive.server2.webui.cors.allowed.methods=GET,POST,DELETE,HEAD
hive.server2.webui.cors.allowed.origins=*
hive.server2.webui.enable.cors=false
hive.server2.webui.host=0.0.0.0
hive.server2.webui.max.historic.queries=25
hive.server2.webui.max.threads=50
hive.server2.webui.port=10002
hive.server2.webui.spnego.principal=HTTP/_HOST@EXAMPLE.COM
hive.server2.webui.use.pam=false
hive.server2.webui.use.spnego=false
hive.server2.webui.use.ssl=false
hive.server2.wm.allow.any.pool.via.jdbc=false
hive.server2.wm.pool.metrics=true
hive.server2.wm.worker.threads=4
hive.server2.xsrf.filter.enabled=false
hive.server2.zookeeper.namespace=hiveserver2
hive.server2.zookeeper.publish.configs=true
hive.service.metrics.class=org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
hive.service.metrics.codahale.reporter.classes=org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter, org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter
hive.service.metrics.file.frequency=5000ms
hive.service.metrics.file.location=/tmp/report.json
hive.service.metrics.hadoop2.component=hive
hive.service.metrics.hadoop2.frequency=30s
hive.session.history.enabled=false
hive.session.id=6e0c6736-c50a-421c-bfc7-5bc34a910619
hive.session.silent=false
hive.skewjoin.key=100000
hive.skewjoin.mapjoin.map.tasks=10000
hive.skewjoin.mapjoin.min.split=33554432
hive.smbjoin.cache.rows=10000
hive.spark.client.connect.timeout=1000ms
hive.spark.client.future.timeout=60s
hive.spark.client.rpc.max.size=52428800
hive.spark.client.rpc.sasl.mechanisms=DIGEST-MD5
hive.spark.client.rpc.threads=8
hive.spark.client.secret.bits=256
hive.spark.client.server.connect.timeout=90000ms
hive.spark.dynamic.partition.pruning=false
hive.spark.dynamic.partition.pruning.map.join.only=false
hive.spark.dynamic.partition.pruning.max.data.size=104857600
hive.spark.exec.inplace.progress=true
hive.spark.explain.user=false
hive.spark.job.max.tasks=-1
hive.spark.job.monitor.timeout=60s
hive.spark.optimize.shuffle.serde=false
hive.spark.rsc.conf.list=hive.spark.optimize.shuffle.serde,hive.spark.client.future.timeout
hive.spark.stage.max.tasks=-1
hive.spark.use.groupby.shuffle=true
hive.spark.use.op.stats=true
hive.spark.use.ts.stats.for.mapjoin=false
hive.ssl.protocol.blacklist=SSLv2,SSLv3
hive.stageid.rearrange=none
hive.start.cleanup.scratchdir=false
hive.stats.autogather=true
hive.stats.collect.scancols=false
hive.stats.collect.tablekeys=false
hive.stats.column.autogather=true
hive.stats.correlated.multi.key.joins=true
hive.stats.dbclass=fs
hive.stats.deserialization.factor=10.0
hive.stats.estimate=true
hive.stats.fetch.bitvector=false
hive.stats.fetch.column.stats=false
hive.stats.filter.in.factor=1.0
hive.stats.filter.in.min.ratio=0.05
hive.stats.gather.num.threads=10
hive.stats.join.factor=1.1
hive.stats.list.num.entries=10
hive.stats.map.num.entries=10
hive.stats.max.variable.length=100
hive.stats.ndv.algo=hll
hive.stats.ndv.error=20.0
hive.stats.ndv.estimate.percent=20.0
hive.stats.num.nulls.estimate.percent=5.0
hive.stats.reliable=false
hive.streaming.auto.flush.check.interval.size=100Mb
hive.streaming.auto.flush.enabled=true
hive.strict.checks.bucketing=true
hive.strict.checks.cartesian.product=false
hive.strict.checks.no.partition.filter=false
hive.strict.checks.orderby.no.limit=false
hive.strict.checks.type.safety=true
hive.support.concurrency=true
hive.support.quoted.identifiers=column
hive.support.special.characters.tablename=true
hive.test.authz.sstd.hs2.mode=false
hive.test.bucketcodec.version=1
hive.test.fail.compaction=false
hive.test.fail.heartbeater=false
hive.test.mode=false
hive.test.mode.prefix=test_
hive.test.mode.samplefreq=32
hive.test.rollbacktxn=false
hive.test.vectorization.suppress.explain.execution.mode=false
hive.test.vectorized.adaptor.override=false
hive.test.vectorized.execution.enabled.override=none
hive.test.vectorizer.suppress.fatal.exceptions=true
hive.testing.remove.logs=true
hive.testing.short.logs=false
hive.tez.auto.reducer.parallelism=false
hive.tez.bigtable.minsize.semijoin.reduction=100000000
hive.tez.bloom.filter.factor=1.0
hive.tez.bmj.use.subcache=true
hive.tez.bucket.pruning=false
hive.tez.bucket.pruning.compat=true
hive.tez.cartesian-product.enabled=false
hive.tez.container.max.java.heap.fraction=0.8
hive.tez.container.size=-1
hive.tez.cpu.vcores=-1
hive.tez.dag.status.check.interval=500ms
hive.tez.dynamic.partition.pruning=true
hive.tez.dynamic.partition.pruning.max.data.size=104857600
hive.tez.dynamic.partition.pruning.max.event.size=1048576
hive.tez.dynamic.semijoin.reduction=true
hive.tez.dynamic.semijoin.reduction.for.dpp.factor=1.0
hive.tez.dynamic.semijoin.reduction.for.mapjoin=false
hive.tez.dynamic.semijoin.reduction.threshold=0.5
hive.tez.enable.memory.manager=true
hive.tez.exec.inplace.progress=true
hive.tez.exec.print.summary=false
hive.tez.hs2.user.access=true
hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
hive.tez.input.generate.consistent.splits=true
hive.tez.llap.min.reducer.per.executor=0.95
hive.tez.log.level=INFO
hive.tez.max.bloom.filter.entries=100000000
hive.tez.max.partition.factor=2.0
hive.tez.min.bloom.filter.entries=1000000
hive.tez.min.partition.factor=0.25
hive.tez.session.events.print.summary=none
hive.tez.smb.number.waves=0.5
hive.tez.task.scale.memory.reserve-fraction.min=0.3
hive.tez.task.scale.memory.reserve.fraction=-1.0
hive.tez.task.scale.memory.reserve.fraction.max=0.5
hive.timedout.txn.reaper.interval=180s
hive.timedout.txn.reaper.start=100s
hive.transactional.concatenate.noblock=false
hive.transactional.events.mem=10000000
hive.transactional.table.scan=false
hive.transform.escape.input=false
hive.transpose.aggr.join=false
hive.trigger.validation.interval=500ms
hive.txn.heartbeat.threadpool.size=5
hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager
hive.txn.manager.dump.lock.state.on.acquire.timeout=false
hive.txn.max.open.batch=1000
hive.txn.operational.properties=1
hive.txn.strict.locking.mode=true
hive.txn.timeout=300s
hive.txn.xlock.iow=true
hive.typecheck.on.insert=true
hive.udtf.auto.progress=false
hive.unlock.numretries=10
hive.use.orc.codec.pool=false
hive.user.install.directory=/user/
hive.variable.substitute=true
hive.variable.substitute.depth=40
hive.vectorized.adaptor.suppress.evaluate.exceptions=false
hive.vectorized.adaptor.usage.mode=all
hive.vectorized.complex.types.enabled=true
hive.vectorized.execution.enabled=true
hive.vectorized.execution.mapjoin.minmax.enabled=false
hive.vectorized.execution.mapjoin.native.enabled=true
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled=false
hive.vectorized.execution.mapjoin.native.multikey.only.enabled=false
hive.vectorized.execution.mapjoin.overflow.repeated.threshold=-1
hive.vectorized.execution.ptf.enabled=true
hive.vectorized.execution.reduce.enabled=true
hive.vectorized.execution.reduce.groupby.enabled=true
hive.vectorized.execution.reducesink.new.enabled=true
hive.vectorized.groupby.checkinterval=100000
hive.vectorized.groupby.complex.types.enabled=true
hive.vectorized.groupby.flush.percent=0.1
hive.vectorized.groupby.maxentries=1000000
hive.vectorized.if.expr.mode=better
hive.vectorized.input.format.supports.enabled=decimal_64
hive.vectorized.ptf.max.memory.buffering.batch.count=25
hive.vectorized.reuse.scratch.columns=true
hive.vectorized.row.identifier.enabled=true
hive.vectorized.row.serde.inputformat.excludes=org.apache.parquet.hadoop.ParquetInputFormat,org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
hive.vectorized.testing.reducer.batch.size=-1
hive.vectorized.use.checked.expressions=false
hive.vectorized.use.row.serde.deserialize=true
hive.vectorized.use.vector.serde.deserialize=true
hive.vectorized.use.vectorized.input.format=true
hive.writeset.reaper.interval=60s
hive.zookeeper.clean.extra.nodes=false
hive.zookeeper.client.port=2181
hive.zookeeper.connection.basesleeptime=1000ms
hive.zookeeper.connection.max.retries=3
hive.zookeeper.connection.timeout=15s
hive.zookeeper.namespace=hive_zookeeper_namespace
hive.zookeeper.session.timeout=1200000ms
httpfs.buffer.size=4096
javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.api.jdo.JDOPersistenceManagerFactory
javax.jdo.option.ConnectionDriverName=com.mysql.cj.jdbc.Driver
javax.jdo.option.ConnectionURL=jdbc:mysql://lluyllucucha/hue?createDatabaseIfNotExist=true
javax.jdo.option.ConnectionUserName=hue
javax.jdo.option.DetachAllOnCommit=true
javax.jdo.option.Multithreaded=true
javax.jdo.option.NonTransactionalRead=true
mapred.bin.path=/opt/hadoop/bin/mapred
mapreduce.input.fileinputformat.split.maxsize=256000000
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.minsize.per.node=1
mapreduce.input.fileinputformat.split.minsize.per.rack=1
mapreduce.job.reduces=-1
nfs.allow.insecure.ports=true
nfs.dump.dir=/tmp/.hdfs-nfs
nfs.mountd.port=4242
nfs.rtmax=1048576
nfs.server.port=2049
nfs.wtmax=1048576
parquet.memory.pool.ratio=0.5
silent=off
stream.stderr.reporter.enabled=true
stream.stderr.reporter.prefix=reporter:
system:java.io.tmpdir=/tmp/hive/java
system:user.name=${user.name}
yarn.bin.path=/opt/hadoop/bin/yarn
env:CLASSPATH=/opt/hadoop/hive/conf:/opt/hadoop/hive/lib/HikariCP-2.6.1.jar:/opt/hadoop/hive/lib/JavaEWAH-0.3.2.jar:/opt/hadoop/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hadoop/hive/lib/ST4-4.0.4.jar:/opt/hadoop/hive/lib/accumulo-core-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-fate-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-start-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-trace-1.7.3.jar:/opt/hadoop/hive/lib/aircompressor-0.10.jar:/opt/hadoop/hive/lib/ant-1.9.1.jar:/opt/hadoop/hive/lib/ant-launcher-1.9.1.jar:/opt/hadoop/hive/lib/antlr-runtime-3.5.2.jar:/opt/hadoop/hive/lib/antlr4-runtime-4.5.jar:/opt/hadoop/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hadoop/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/arrow-format-0.8.0.jar:/opt/hadoop/hive/lib/arrow-memory-0.8.0.jar:/opt/hadoop/hive/lib/arrow-vector-0.8.0.jar:/opt/hadoop/hive/lib/asm-5.0.1.jar:/opt/hadoop/hive/lib/asm-commons-5.0.1.jar:/opt/hadoop/hive/lib/asm-tree-5.0.1.jar:/opt/hadoop/hive/lib/audience-annotations-0.5.0.jar:/opt/hadoop/hive/lib/avatica-1.11.0.jar:/opt/hadoop/hive/lib/avro-1.8.2.jar:/opt/hadoop/hive/lib/avro-ipc-1.8.2.jar:/opt/hadoop/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hadoop/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/hive/lib/calcite-core-1.16.0.jar:/opt/hadoop/hive/lib/calcite-druid-1.16.0.jar:/opt/hadoop/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hadoop/hive/lib/chill-java-0.8.4.jar:/opt/hadoop/hive/lib/chill_2.11-0.8.4.jar:/opt/hadoop/hive/lib/commons-cli-1.2.jar:/opt/hadoop/hive/lib/commons-codec-1.15.jar:/opt/hadoop/hive/lib/commons-collections4-4.1.jar:/opt/hadoop/hive/lib/commons-compiler-2.7.6.jar:/opt/hadoop/hive/lib/commons-compress-1.19.jar:/opt/hadoop/hive/lib/commons-crypto-1.0.0.jar:/opt/hadoop/hive/lib/commons-dbcp-1.4.jar:/opt/hadoop/hive/lib/commons-io-2.6.jar:/opt/hadoop/hive/lib/commons-lang-2.6.jar:/opt/hadoop/hive/lib/commons-lang3-3.9.jar:/opt/hadoop/hive/lib/commons-logging-1.0.4.jar:/opt/hadoop/hive/lib/commons-math-2.1.jar:/opt/hadoop/hive/lib/commons-math3-3.6.1.jar:/opt/hadoop/hive/lib/commons-pool-1.5.4.jar:/opt/hadoop/hive/lib/commons-vfs2-2.1.jar:/opt/hadoop/hive/lib/compress-lzf-1.0.3.jar:/opt/hadoop/hive/lib/curator-client-2.12.0.jar:/opt/hadoop/hive/lib/curator-framework-2.12.0.jar:/opt/hadoop/hive/lib/curator-recipes-2.12.0.jar:/opt/hadoop/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hadoop/hive/lib/datanucleus-core-4.1.17.jar:/opt/hadoop/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hadoop/hive/lib/derby-10.14.1.0.jar:/opt/hadoop/hive/lib/disruptor-3.3.6.jar:/opt/hadoop/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hadoop/hive/lib/ecj-4.4.2.jar:/opt/hadoop/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hadoop/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hadoop/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hadoop/hive/lib/groovy-all-2.4.11.jar:/opt/hadoop/hive/lib/gson-2.2.4.jar:/opt/hadoop/hive/lib/guava-19.0.jar:/opt/hadoop/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hadoop/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hadoop/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hadoop/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hadoop/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hadoop/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-beeline-3.1.3.jar:/opt/hadoop/hive/lib/hive-classification-3.1.3.jar:/opt/hadoop/hive/lib/hive-cli-3.1.3.jar:/opt/hadoop/hive/lib/hive-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-contrib-3.1.3.jar:/opt/hadoop/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-exec-3.1.3.jar:/opt/hadoop/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hadoop/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hadoop/hive/lib/hive-hplsql-3.1.3.jar:/opt/hadoop/hive/lib/hive-jdbc-3.1.3.jar:/opt/hadoop/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hadoop/hive/lib/hive-llap-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-server-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hadoop/hive/lib/hive-metastore-3.1.3.jar:/opt/hadoop/hive/lib/hive-serde-3.1.3.jar:/opt/hadoop/hive/lib/hive-service-3.1.3.jar:/opt/hadoop/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hadoop/hive/lib/hive-spark-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hadoop/hive/lib/hive-storage-api-2.7.0.jar:/opt/hadoop/hive/lib/hive-streaming-3.1.3.jar:/opt/hadoop/hive/lib/hive-testutils-3.1.3.jar:/opt/hadoop/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hadoop/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hadoop/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hadoop/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hadoop/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hadoop/hive/lib/hppc-0.7.2.jar:/opt/hadoop/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hadoop/hive/lib/httpclient-4.5.13.jar:/opt/hadoop/hive/lib/httpcore-4.4.13.jar:/opt/hadoop/hive/lib/ivy-2.4.0.jar:/opt/hadoop/hive/lib/jackson-annotations-2.12.0.jar:/opt/hadoop/hive/lib/jackson-core-2.12.0.jar:/opt/hadoop/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/hive/lib/jackson-databind-2.12.0.jar:/opt/hadoop/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hadoop/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hadoop/hive/lib/jamon-runtime-2.3.1.jar:/opt/hadoop/hive/lib/janino-2.7.6.jar:/opt/hadoop/hive/lib/javassist-3.20.0-GA.jar:/opt/hadoop/hive/lib/javax.annotation-api-1.2.jar:/opt/hadoop/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hadoop/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hadoop/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hadoop/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hadoop/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hadoop/hive/lib/javolution-5.5.1.jar:/opt/hadoop/hive/lib/jaxb-api-2.2.11.jar:/opt/hadoop/hive/lib/jcodings-1.0.18.jar:/opt/hadoop/hive/lib/jcommander-1.32.jar:/opt/hadoop/hive/lib/jdo-api-3.0.1.jar:/opt/hadoop/hive/lib/jersey-client-2.25.1.jar:/opt/hadoop/hive/lib/jersey-common-2.25.1.jar:/opt/hadoop/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hadoop/hive/lib/jersey-guava-2.25.1.jar:/opt/hadoop/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hadoop/hive/lib/jersey-server-2.25.1.jar:/opt/hadoop/hive/lib/jettison-1.1.jar:/opt/hadoop/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-schemas-3.1.jar:/opt/hadoop/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jline-2.12.jar:/opt/hadoop/hive/lib/joda-time-2.9.9.jar:/opt/hadoop/hive/lib/jodd-core-3.5.2.jar:/opt/hadoop/hive/lib/joni-2.1.11.jar:/opt/hadoop/hive/lib/jpam-1.1.jar:/opt/hadoop/hive/lib/json-1.8.jar:/opt/hadoop/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hadoop/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hadoop/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hadoop/hive/lib/jsr305-3.0.0.jar:/opt/hadoop/hive/lib/jta-1.1.jar:/opt/hadoop/hive/lib/kryo-shaded-3.0.3.jar:/opt/hadoop/hive/lib/libfb303-0.9.3.jar:/opt/hadoop/hive/lib/libthrift-0.9.3.jar:/opt/hadoop/hive/lib/lz4-java-1.4.0.jar:/opt/hadoop/hive/lib/memory-0.9.0.jar:/opt/hadoop/hive/lib/metrics-core-3.1.0.jar:/opt/hadoop/hive/lib/metrics-graphite-3.1.5.jar:/opt/hadoop/hive/lib/metrics-json-3.1.0.jar:/opt/hadoop/hive/lib/metrics-jvm-3.1.0.jar:/opt/hadoop/hive/lib/minlog-1.3.0.jar:/opt/hadoop/hive/lib/mysql-connector-j-8.0.31.jar:/opt/hadoop/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hadoop/hive/lib/netty-3.10.5.Final.jar:/opt/hadoop/hive/lib/netty-all-4.1.17.Final.jar:/opt/hadoop/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hadoop/hive/lib/netty-common-4.1.17.Final.jar:/opt/hadoop/hive/lib/objenesis-2.1.jar:/opt/hadoop/hive/lib/opencsv-2.3.jar:/opt/hadoop/hive/lib/opencsv-3.9.jar:/opt/hadoop/hive/lib/orc-core-1.5.8.jar:/opt/hadoop/hive/lib/orc-shims-1.5.8.jar:/opt/hadoop/hive/lib/orc-tools-1.5.8.jar:/opt/hadoop/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hadoop/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/hive/lib/paranamer-2.7.jar:/opt/hadoop/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hadoop/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hadoop/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hadoop/hive/lib/protobuf-java-2.5.0.jar:/opt/hadoop/hive/lib/py4j-0.10.6.jar:/opt/hadoop/hive/lib/pyrolite-4.13.jar:/opt/hadoop/hive/lib/scala-compiler-2.11.0.jar:/opt/hadoop/hive/lib/scala-library-2.11.8.jar:/opt/hadoop/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hadoop/hive/lib/scala-reflect-2.11.0.jar:/opt/hadoop/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hadoop/hive/lib/scalap-2.11.0.jar:/opt/hadoop/hive/lib/sketches-core-0.9.0.jar:/opt/hadoop/hive/lib/snappy-java-1.1.4.jar:/opt/hadoop/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hadoop/hive/lib/sqlline-1.3.0.jar:/opt/hadoop/hive/lib/stax-api-1.0.1.jar:/opt/hadoop/hive/lib/stream-2.7.0.jar:/opt/hadoop/hive/lib/super-csv-2.2.0.jar:/opt/hadoop/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hadoop/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hadoop/hive/lib/tempus-fugit-1.1.jar:/opt/hadoop/hive/lib/threetenbp-1.3.5.jar:/opt/hadoop/hive/lib/transaction-api-1.1.jar:/opt/hadoop/hive/lib/unused-1.0.0.jar:/opt/hadoop/hive/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/hive/lib/velocity-1.7.jar:/opt/hadoop/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hadoop/hive/lib/xz-1.5.jar:/opt/hadoop/hive/lib/zookeeper-3.4.6.jar:/opt/hadoop/hive/lib/zstd-jni-1.3.2-2.jar:/opt/java/jdk1.8.0_361/lib/tools.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.3.4.jar:/opt/hadoop/hbase/conf:/opt/hadoop/hbase/lib/shaded-clients/hbase-shaded-mapreduce-2.5.3.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/audience-annotations-0.13.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/commons-logging-1.2.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/jcl-over-slf4j-1.7.33.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/jul-to-slf4j-1.7.33.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-api-1.15.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-context-1.15.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-semconv-1.15.0-alpha.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar:/opt/hadoop/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hadoop/hive/lib/log4j-api-2.17.1.jar:/opt/hadoop/hive/lib/log4j-core-2.17.1.jar:/opt/hadoop/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hadoop/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*
env:CONDA3_HOME=/home/ernestosegundo/anaconda3
env:DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus
env:HADOOP_CLASSPATH=/etc/tez/conf:/opt/hadoop/hive/conf:/opt/hadoop/hive/lib/HikariCP-2.6.1.jar:/opt/hadoop/hive/lib/JavaEWAH-0.3.2.jar:/opt/hadoop/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hadoop/hive/lib/ST4-4.0.4.jar:/opt/hadoop/hive/lib/accumulo-core-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-fate-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-start-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-trace-1.7.3.jar:/opt/hadoop/hive/lib/aircompressor-0.10.jar:/opt/hadoop/hive/lib/ant-1.9.1.jar:/opt/hadoop/hive/lib/ant-launcher-1.9.1.jar:/opt/hadoop/hive/lib/antlr-runtime-3.5.2.jar:/opt/hadoop/hive/lib/antlr4-runtime-4.5.jar:/opt/hadoop/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hadoop/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/arrow-format-0.8.0.jar:/opt/hadoop/hive/lib/arrow-memory-0.8.0.jar:/opt/hadoop/hive/lib/arrow-vector-0.8.0.jar:/opt/hadoop/hive/lib/asm-5.0.1.jar:/opt/hadoop/hive/lib/asm-commons-5.0.1.jar:/opt/hadoop/hive/lib/asm-tree-5.0.1.jar:/opt/hadoop/hive/lib/audience-annotations-0.5.0.jar:/opt/hadoop/hive/lib/avatica-1.11.0.jar:/opt/hadoop/hive/lib/avro-1.8.2.jar:/opt/hadoop/hive/lib/avro-ipc-1.8.2.jar:/opt/hadoop/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hadoop/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/hive/lib/calcite-core-1.16.0.jar:/opt/hadoop/hive/lib/calcite-druid-1.16.0.jar:/opt/hadoop/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hadoop/hive/lib/chill-java-0.8.4.jar:/opt/hadoop/hive/lib/chill_2.11-0.8.4.jar:/opt/hadoop/hive/lib/commons-cli-1.2.jar:/opt/hadoop/hive/lib/commons-codec-1.15.jar:/opt/hadoop/hive/lib/commons-collections4-4.1.jar:/opt/hadoop/hive/lib/commons-compiler-2.7.6.jar:/opt/hadoop/hive/lib/commons-compress-1.19.jar:/opt/hadoop/hive/lib/commons-crypto-1.0.0.jar:/opt/hadoop/hive/lib/commons-dbcp-1.4.jar:/opt/hadoop/hive/lib/commons-io-2.6.jar:/opt/hadoop/hive/lib/commons-lang-2.6.jar:/opt/hadoop/hive/lib/commons-lang3-3.9.jar:/opt/hadoop/hive/lib/commons-logging-1.0.4.jar:/opt/hadoop/hive/lib/commons-math-2.1.jar:/opt/hadoop/hive/lib/commons-math3-3.6.1.jar:/opt/hadoop/hive/lib/commons-pool-1.5.4.jar:/opt/hadoop/hive/lib/commons-vfs2-2.1.jar:/opt/hadoop/hive/lib/compress-lzf-1.0.3.jar:/opt/hadoop/hive/lib/curator-client-2.12.0.jar:/opt/hadoop/hive/lib/curator-framework-2.12.0.jar:/opt/hadoop/hive/lib/curator-recipes-2.12.0.jar:/opt/hadoop/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hadoop/hive/lib/datanucleus-core-4.1.17.jar:/opt/hadoop/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hadoop/hive/lib/derby-10.14.1.0.jar:/opt/hadoop/hive/lib/disruptor-3.3.6.jar:/opt/hadoop/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hadoop/hive/lib/ecj-4.4.2.jar:/opt/hadoop/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hadoop/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hadoop/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hadoop/hive/lib/groovy-all-2.4.11.jar:/opt/hadoop/hive/lib/gson-2.2.4.jar:/opt/hadoop/hive/lib/guava-19.0.jar:/opt/hadoop/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hadoop/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hadoop/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hadoop/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hadoop/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hadoop/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-beeline-3.1.3.jar:/opt/hadoop/hive/lib/hive-classification-3.1.3.jar:/opt/hadoop/hive/lib/hive-cli-3.1.3.jar:/opt/hadoop/hive/lib/hive-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-contrib-3.1.3.jar:/opt/hadoop/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-exec-3.1.3.jar:/opt/hadoop/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hadoop/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hadoop/hive/lib/hive-hplsql-3.1.3.jar:/opt/hadoop/hive/lib/hive-jdbc-3.1.3.jar:/opt/hadoop/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hadoop/hive/lib/hive-llap-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-server-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hadoop/hive/lib/hive-metastore-3.1.3.jar:/opt/hadoop/hive/lib/hive-serde-3.1.3.jar:/opt/hadoop/hive/lib/hive-service-3.1.3.jar:/opt/hadoop/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hadoop/hive/lib/hive-spark-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hadoop/hive/lib/hive-storage-api-2.7.0.jar:/opt/hadoop/hive/lib/hive-streaming-3.1.3.jar:/opt/hadoop/hive/lib/hive-testutils-3.1.3.jar:/opt/hadoop/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hadoop/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hadoop/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hadoop/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hadoop/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hadoop/hive/lib/hppc-0.7.2.jar:/opt/hadoop/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hadoop/hive/lib/httpclient-4.5.13.jar:/opt/hadoop/hive/lib/httpcore-4.4.13.jar:/opt/hadoop/hive/lib/ivy-2.4.0.jar:/opt/hadoop/hive/lib/jackson-annotations-2.12.0.jar:/opt/hadoop/hive/lib/jackson-core-2.12.0.jar:/opt/hadoop/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/hive/lib/jackson-databind-2.12.0.jar:/opt/hadoop/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hadoop/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hadoop/hive/lib/jamon-runtime-2.3.1.jar:/opt/hadoop/hive/lib/janino-2.7.6.jar:/opt/hadoop/hive/lib/javassist-3.20.0-GA.jar:/opt/hadoop/hive/lib/javax.annotation-api-1.2.jar:/opt/hadoop/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hadoop/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hadoop/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hadoop/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hadoop/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hadoop/hive/lib/javolution-5.5.1.jar:/opt/hadoop/hive/lib/jaxb-api-2.2.11.jar:/opt/hadoop/hive/lib/jcodings-1.0.18.jar:/opt/hadoop/hive/lib/jcommander-1.32.jar:/opt/hadoop/hive/lib/jdo-api-3.0.1.jar:/opt/hadoop/hive/lib/jersey-client-2.25.1.jar:/opt/hadoop/hive/lib/jersey-common-2.25.1.jar:/opt/hadoop/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hadoop/hive/lib/jersey-guava-2.25.1.jar:/opt/hadoop/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hadoop/hive/lib/jersey-server-2.25.1.jar:/opt/hadoop/hive/lib/jettison-1.1.jar:/opt/hadoop/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-schemas-3.1.jar:/opt/hadoop/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jline-2.12.jar:/opt/hadoop/hive/lib/joda-time-2.9.9.jar:/opt/hadoop/hive/lib/jodd-core-3.5.2.jar:/opt/hadoop/hive/lib/joni-2.1.11.jar:/opt/hadoop/hive/lib/jpam-1.1.jar:/opt/hadoop/hive/lib/json-1.8.jar:/opt/hadoop/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hadoop/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hadoop/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hadoop/hive/lib/jsr305-3.0.0.jar:/opt/hadoop/hive/lib/jta-1.1.jar:/opt/hadoop/hive/lib/kryo-shaded-3.0.3.jar:/opt/hadoop/hive/lib/libfb303-0.9.3.jar:/opt/hadoop/hive/lib/libthrift-0.9.3.jar:/opt/hadoop/hive/lib/lz4-java-1.4.0.jar:/opt/hadoop/hive/lib/memory-0.9.0.jar:/opt/hadoop/hive/lib/metrics-core-3.1.0.jar:/opt/hadoop/hive/lib/metrics-graphite-3.1.5.jar:/opt/hadoop/hive/lib/metrics-json-3.1.0.jar:/opt/hadoop/hive/lib/metrics-jvm-3.1.0.jar:/opt/hadoop/hive/lib/minlog-1.3.0.jar:/opt/hadoop/hive/lib/mysql-connector-j-8.0.31.jar:/opt/hadoop/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hadoop/hive/lib/netty-3.10.5.Final.jar:/opt/hadoop/hive/lib/netty-all-4.1.17.Final.jar:/opt/hadoop/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hadoop/hive/lib/netty-common-4.1.17.Final.jar:/opt/hadoop/hive/lib/objenesis-2.1.jar:/opt/hadoop/hive/lib/opencsv-2.3.jar:/opt/hadoop/hive/lib/opencsv-3.9.jar:/opt/hadoop/hive/lib/orc-core-1.5.8.jar:/opt/hadoop/hive/lib/orc-shims-1.5.8.jar:/opt/hadoop/hive/lib/orc-tools-1.5.8.jar:/opt/hadoop/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hadoop/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/hive/lib/paranamer-2.7.jar:/opt/hadoop/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hadoop/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hadoop/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hadoop/hive/lib/protobuf-java-2.5.0.jar:/opt/hadoop/hive/lib/py4j-0.10.6.jar:/opt/hadoop/hive/lib/pyrolite-4.13.jar:/opt/hadoop/hive/lib/scala-compiler-2.11.0.jar:/opt/hadoop/hive/lib/scala-library-2.11.8.jar:/opt/hadoop/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hadoop/hive/lib/scala-reflect-2.11.0.jar:/opt/hadoop/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hadoop/hive/lib/scalap-2.11.0.jar:/opt/hadoop/hive/lib/sketches-core-0.9.0.jar:/opt/hadoop/hive/lib/snappy-java-1.1.4.jar:/opt/hadoop/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hadoop/hive/lib/sqlline-1.3.0.jar:/opt/hadoop/hive/lib/stax-api-1.0.1.jar:/opt/hadoop/hive/lib/stream-2.7.0.jar:/opt/hadoop/hive/lib/super-csv-2.2.0.jar:/opt/hadoop/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hadoop/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hadoop/hive/lib/tempus-fugit-1.1.jar:/opt/hadoop/hive/lib/threetenbp-1.3.5.jar:/opt/hadoop/hive/lib/transaction-api-1.1.jar:/opt/hadoop/hive/lib/unused-1.0.0.jar:/opt/hadoop/hive/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/hive/lib/velocity-1.7.jar:/opt/hadoop/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hadoop/hive/lib/xz-1.5.jar:/opt/hadoop/hive/lib/zookeeper-3.4.6.jar:/opt/hadoop/hive/lib/zstd-jni-1.3.2-2.jar::/opt/java/jdk1.8.0_361/lib/tools.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.3.4.jar:/opt/hadoop/hbase/conf:/opt/hadoop/hbase/lib/shaded-clients/hbase-shaded-mapreduce-2.5.3.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/audience-annotations-0.13.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/commons-logging-1.2.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/jcl-over-slf4j-1.7.33.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/jul-to-slf4j-1.7.33.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-api-1.15.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-context-1.15.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-semconv-1.15.0-alpha.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar::/opt/hadoop/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hadoop/hive/lib/log4j-api-2.17.1.jar:/opt/hadoop/hive/lib/log4j-core-2.17.1.jar:/opt/hadoop/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hadoop/hive/lib/log4j-web-2.17.1.jar
env:HADOOP_CLIENT_OPTS= -Dproc_hivecli  -Dlog4j2.formatMsgNoLookups=true -Dlog4j.configurationFile=hive-log4j2.properties  -Djava.util.logging.config.file=/opt/hadoop/hive/conf/parquet-logging.properties  
env:HADOOP_COMMON_HOME=/opt/hadoop
env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
env:HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
env:HADOOP_ENV_PROCESSED=true
env:HADOOP_HDFS_HOME=/opt/hadoop
env:HADOOP_HEAPSIZE=256m
env:HADOOP_HOME=/opt/hadoop
env:HADOOP_HOME_WARN_SUPPRESS=true
env:HADOOP_MAPRED_HOME=/opt/hadoop
env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib  -Dproc_hivecli  -Dlog4j2.formatMsgNoLookups=true -Dlog4j.configurationFile=hive-log4j2.properties  -Djava.util.logging.config.file=/opt/hadoop/hive/conf/parquet-logging.properties   -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Xmx256m -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=ernestosegundo -Dhadoop.root.logger=WARN,DRFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender
env:HADOOP_OS_TYPE=Linux
env:HADOOP_ROOT_LOGGER=WARN,DRFA
env:HADOOP_USER_CLASSPATH_FIRST=true
env:HADOOP_YARN_HOME=/opt/hadoop
env:HBASE_HOME=/opt/hadoop/hbase
env:HIVE_AUX_JARS_PATH=
env:HIVE_CONF_DIR=/opt/hadoop/hive/conf
env:HIVE_HOME=/opt/hadoop/hive
env:HOME=/home/ernestosegundo
env:HOME_SCRIPTS=/scripts
env:JAVA_HOME=/opt/java/jdk1.8.0_361
env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native:
env:LANG=C
env:LD_LIBRARY_PATH=/opt/hadoop/lib/native
env:LOGNAME=ernestosegundo
env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
env:M2_HOME=/opt/maven
env:MALLOC_ARENA_MAX=4
env:MOTD_SHOWN=pam
env:PATH=/home/ernestosegundo/.local/bin:/opt/maven/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/opt/java/jdk1.8.0_361/bin:/opt/hadoop/bin:/opt/hadoop/sbin:/opt/hadoop/hive/bin:/opt/hadoop/sqoop/bin:/opt/hadoop/zookeeper/bin:/opt/hadoop/spark/bin:/opt/hadoop/spark/sbin:/opt/hadoop/hbase/bin:/home/ernestosegundo/anaconda3/bin:/scripts
env:PWD=/home/ernestosegundo
env:PYSPARK_DRIVER_PYTHON=python3
env:PYSPARK_PYTHON=python3
env:PYTHONPATH=:/opt/hadoop/spark/python
env:PYTHON_VER=python3.9
env:SERVICE_LIST=beeline cleardanglingscratchdir cli fixacidkeyindex help hiveburninclient hiveserver2 hplsql jar lineage llap llapdump llapstatus metastore metatool orcfiledump rcfilecat schemaTool strictmanagedmigration tokentool version 
env:SHELL=/bin/bash
env:SHLVL=1
env:SPARK_DIST_CLASSPATH=/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/java/jdk1.8.0_361/lib/tools.jar
env:SPARK_HOME=/opt/hadoop/spark
env:SQOOP_HOME=/opt/hadoop/sqoop
env:SSH_CLIENT=192.168.1.33 59901 22
env:SSH_CONNECTION=192.168.1.33 59901 192.168.1.101 22
env:SSH_TTY=/dev/pts/4
env:TERM=xterm
env:USER=ernestosegundo
env:XDG_RUNTIME_DIR=/run/user/1000
env:XDG_SESSION_CLASS=user
env:XDG_SESSION_ID=28
env:XDG_SESSION_TYPE=tty
env:ZOOKEEPER_HOME=/opt/hadoop/zookeeper
system:Log4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector
system:awt.toolkit=sun.awt.X11.XToolkit
system:com.zaxxer.hikari.pool_number=2
system:file.encoding=ANSI_X3.4-1968
system:file.encoding.pkg=sun.io
system:file.separator=/
system:hadoop.home.dir=/opt/hadoop
system:hadoop.id.str=ernestosegundo
system:hadoop.log.dir=/opt/hadoop/logs
system:hadoop.log.file=hadoop.log
system:hadoop.policy.file=hadoop-policy.xml
system:hadoop.root.logger=WARN,DRFA
system:hadoop.security.logger=INFO,NullAppender
system:isThreadContextMapInheritable=true
system:java.awt.graphicsenv=sun.awt.X11GraphicsEnvironment
system:java.awt.printerjob=sun.print.PSPrinterJob
system:java.class.path=/opt/hadoop/hive/conf:/opt/hadoop/hive/lib/HikariCP-2.6.1.jar:/opt/hadoop/hive/lib/JavaEWAH-0.3.2.jar:/opt/hadoop/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hadoop/hive/lib/ST4-4.0.4.jar:/opt/hadoop/hive/lib/accumulo-core-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-fate-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-start-1.7.3.jar:/opt/hadoop/hive/lib/accumulo-trace-1.7.3.jar:/opt/hadoop/hive/lib/aircompressor-0.10.jar:/opt/hadoop/hive/lib/ant-1.9.1.jar:/opt/hadoop/hive/lib/ant-launcher-1.9.1.jar:/opt/hadoop/hive/lib/antlr-runtime-3.5.2.jar:/opt/hadoop/hive/lib/antlr4-runtime-4.5.jar:/opt/hadoop/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hadoop/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/arrow-format-0.8.0.jar:/opt/hadoop/hive/lib/arrow-memory-0.8.0.jar:/opt/hadoop/hive/lib/arrow-vector-0.8.0.jar:/opt/hadoop/hive/lib/asm-5.0.1.jar:/opt/hadoop/hive/lib/asm-commons-5.0.1.jar:/opt/hadoop/hive/lib/asm-tree-5.0.1.jar:/opt/hadoop/hive/lib/audience-annotations-0.5.0.jar:/opt/hadoop/hive/lib/avatica-1.11.0.jar:/opt/hadoop/hive/lib/avro-1.8.2.jar:/opt/hadoop/hive/lib/avro-ipc-1.8.2.jar:/opt/hadoop/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hadoop/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/hive/lib/calcite-core-1.16.0.jar:/opt/hadoop/hive/lib/calcite-druid-1.16.0.jar:/opt/hadoop/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hadoop/hive/lib/chill-java-0.8.4.jar:/opt/hadoop/hive/lib/chill_2.11-0.8.4.jar:/opt/hadoop/hive/lib/commons-cli-1.2.jar:/opt/hadoop/hive/lib/commons-codec-1.15.jar:/opt/hadoop/hive/lib/commons-collections4-4.1.jar:/opt/hadoop/hive/lib/commons-compiler-2.7.6.jar:/opt/hadoop/hive/lib/commons-compress-1.19.jar:/opt/hadoop/hive/lib/commons-crypto-1.0.0.jar:/opt/hadoop/hive/lib/commons-dbcp-1.4.jar:/opt/hadoop/hive/lib/commons-io-2.6.jar:/opt/hadoop/hive/lib/commons-lang-2.6.jar:/opt/hadoop/hive/lib/commons-lang3-3.9.jar:/opt/hadoop/hive/lib/commons-logging-1.0.4.jar:/opt/hadoop/hive/lib/commons-math-2.1.jar:/opt/hadoop/hive/lib/commons-math3-3.6.1.jar:/opt/hadoop/hive/lib/commons-pool-1.5.4.jar:/opt/hadoop/hive/lib/commons-vfs2-2.1.jar:/opt/hadoop/hive/lib/compress-lzf-1.0.3.jar:/opt/hadoop/hive/lib/curator-client-2.12.0.jar:/opt/hadoop/hive/lib/curator-framework-2.12.0.jar:/opt/hadoop/hive/lib/curator-recipes-2.12.0.jar:/opt/hadoop/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hadoop/hive/lib/datanucleus-core-4.1.17.jar:/opt/hadoop/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hadoop/hive/lib/derby-10.14.1.0.jar:/opt/hadoop/hive/lib/disruptor-3.3.6.jar:/opt/hadoop/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hadoop/hive/lib/ecj-4.4.2.jar:/opt/hadoop/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hadoop/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hadoop/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hadoop/hive/lib/groovy-all-2.4.11.jar:/opt/hadoop/hive/lib/gson-2.2.4.jar:/opt/hadoop/hive/lib/guava-19.0.jar:/opt/hadoop/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hadoop/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hadoop/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hadoop/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hadoop/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hadoop/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hadoop/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-beeline-3.1.3.jar:/opt/hadoop/hive/lib/hive-classification-3.1.3.jar:/opt/hadoop/hive/lib/hive-cli-3.1.3.jar:/opt/hadoop/hive/lib/hive-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-contrib-3.1.3.jar:/opt/hadoop/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-exec-3.1.3.jar:/opt/hadoop/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hadoop/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hadoop/hive/lib/hive-hplsql-3.1.3.jar:/opt/hadoop/hive/lib/hive-jdbc-3.1.3.jar:/opt/hadoop/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hadoop/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hadoop/hive/lib/hive-llap-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-server-3.1.3.jar:/opt/hadoop/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hadoop/hive/lib/hive-metastore-3.1.3.jar:/opt/hadoop/hive/lib/hive-serde-3.1.3.jar:/opt/hadoop/hive/lib/hive-service-3.1.3.jar:/opt/hadoop/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-common-3.1.3.jar:/opt/hadoop/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hadoop/hive/lib/hive-spark-client-3.1.3.jar:/opt/hadoop/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hadoop/hive/lib/hive-storage-api-2.7.0.jar:/opt/hadoop/hive/lib/hive-streaming-3.1.3.jar:/opt/hadoop/hive/lib/hive-testutils-3.1.3.jar:/opt/hadoop/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hadoop/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hadoop/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hadoop/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hadoop/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hadoop/hive/lib/hppc-0.7.2.jar:/opt/hadoop/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hadoop/hive/lib/httpclient-4.5.13.jar:/opt/hadoop/hive/lib/httpcore-4.4.13.jar:/opt/hadoop/hive/lib/ivy-2.4.0.jar:/opt/hadoop/hive/lib/jackson-annotations-2.12.0.jar:/opt/hadoop/hive/lib/jackson-core-2.12.0.jar:/opt/hadoop/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/hive/lib/jackson-databind-2.12.0.jar:/opt/hadoop/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hadoop/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hadoop/hive/lib/jamon-runtime-2.3.1.jar:/opt/hadoop/hive/lib/janino-2.7.6.jar:/opt/hadoop/hive/lib/javassist-3.20.0-GA.jar:/opt/hadoop/hive/lib/javax.annotation-api-1.2.jar:/opt/hadoop/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hadoop/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hadoop/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hadoop/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hadoop/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hadoop/hive/lib/javolution-5.5.1.jar:/opt/hadoop/hive/lib/jaxb-api-2.2.11.jar:/opt/hadoop/hive/lib/jcodings-1.0.18.jar:/opt/hadoop/hive/lib/jcommander-1.32.jar:/opt/hadoop/hive/lib/jdo-api-3.0.1.jar:/opt/hadoop/hive/lib/jersey-client-2.25.1.jar:/opt/hadoop/hive/lib/jersey-common-2.25.1.jar:/opt/hadoop/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hadoop/hive/lib/jersey-guava-2.25.1.jar:/opt/hadoop/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hadoop/hive/lib/jersey-server-2.25.1.jar:/opt/hadoop/hive/lib/jettison-1.1.jar:/opt/hadoop/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-schemas-3.1.jar:/opt/hadoop/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/jline-2.12.jar:/opt/hadoop/hive/lib/joda-time-2.9.9.jar:/opt/hadoop/hive/lib/jodd-core-3.5.2.jar:/opt/hadoop/hive/lib/joni-2.1.11.jar:/opt/hadoop/hive/lib/jpam-1.1.jar:/opt/hadoop/hive/lib/json-1.8.jar:/opt/hadoop/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hadoop/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hadoop/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hadoop/hive/lib/jsr305-3.0.0.jar:/opt/hadoop/hive/lib/jta-1.1.jar:/opt/hadoop/hive/lib/kryo-shaded-3.0.3.jar:/opt/hadoop/hive/lib/libfb303-0.9.3.jar:/opt/hadoop/hive/lib/libthrift-0.9.3.jar:/opt/hadoop/hive/lib/lz4-java-1.4.0.jar:/opt/hadoop/hive/lib/memory-0.9.0.jar:/opt/hadoop/hive/lib/metrics-core-3.1.0.jar:/opt/hadoop/hive/lib/metrics-graphite-3.1.5.jar:/opt/hadoop/hive/lib/metrics-json-3.1.0.jar:/opt/hadoop/hive/lib/metrics-jvm-3.1.0.jar:/opt/hadoop/hive/lib/minlog-1.3.0.jar:/opt/hadoop/hive/lib/mysql-connector-j-8.0.31.jar:/opt/hadoop/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hadoop/hive/lib/netty-3.10.5.Final.jar:/opt/hadoop/hive/lib/netty-all-4.1.17.Final.jar:/opt/hadoop/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hadoop/hive/lib/netty-common-4.1.17.Final.jar:/opt/hadoop/hive/lib/objenesis-2.1.jar:/opt/hadoop/hive/lib/opencsv-2.3.jar:/opt/hadoop/hive/lib/opencsv-3.9.jar:/opt/hadoop/hive/lib/orc-core-1.5.8.jar:/opt/hadoop/hive/lib/orc-shims-1.5.8.jar:/opt/hadoop/hive/lib/orc-tools-1.5.8.jar:/opt/hadoop/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hadoop/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/hive/lib/paranamer-2.7.jar:/opt/hadoop/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hadoop/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hadoop/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hadoop/hive/lib/protobuf-java-2.5.0.jar:/opt/hadoop/hive/lib/py4j-0.10.6.jar:/opt/hadoop/hive/lib/pyrolite-4.13.jar:/opt/hadoop/hive/lib/scala-compiler-2.11.0.jar:/opt/hadoop/hive/lib/scala-library-2.11.8.jar:/opt/hadoop/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hadoop/hive/lib/scala-reflect-2.11.0.jar:/opt/hadoop/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hadoop/hive/lib/scalap-2.11.0.jar:/opt/hadoop/hive/lib/sketches-core-0.9.0.jar:/opt/hadoop/hive/lib/snappy-java-1.1.4.jar:/opt/hadoop/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hadoop/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hadoop/hive/lib/sqlline-1.3.0.jar:/opt/hadoop/hive/lib/stax-api-1.0.1.jar:/opt/hadoop/hive/lib/stream-2.7.0.jar:/opt/hadoop/hive/lib/super-csv-2.2.0.jar:/opt/hadoop/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hadoop/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hadoop/hive/lib/tempus-fugit-1.1.jar:/opt/hadoop/hive/lib/threetenbp-1.3.5.jar:/opt/hadoop/hive/lib/transaction-api-1.1.jar:/opt/hadoop/hive/lib/unused-1.0.0.jar:/opt/hadoop/hive/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/hive/lib/velocity-1.7.jar:/opt/hadoop/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hadoop/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hadoop/hive/lib/xz-1.5.jar:/opt/hadoop/hive/lib/zookeeper-3.4.6.jar:/opt/hadoop/hive/lib/zstd-jni-1.3.2-2.jar:/opt/java/jdk1.8.0_361/lib/tools.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.3.4.jar:/opt/hadoop/hbase/conf:/opt/hadoop/hbase/lib/shaded-clients/hbase-shaded-mapreduce-2.5.3.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/audience-annotations-0.13.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/commons-logging-1.2.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/jcl-over-slf4j-1.7.33.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/jul-to-slf4j-1.7.33.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-api-1.15.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-context-1.15.0.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/opentelemetry-semconv-1.15.0-alpha.jar:/opt/hadoop/hbase/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar:/opt/hadoop/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hadoop/hive/lib/log4j-api-2.17.1.jar:/opt/hadoop/hive/lib/log4j-core-2.17.1.jar:/opt/hadoop/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hadoop/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar
system:java.class.version=52.0
system:java.endorsed.dirs=/opt/java/jdk1.8.0_361/jre/lib/endorsed
system:java.ext.dirs=/opt/java/jdk1.8.0_361/jre/lib/ext:/usr/java/packages/lib/ext
system:java.home=/opt/java/jdk1.8.0_361/jre
system:java.io.tmpdir=/tmp
system:java.library.path=/opt/hadoop/lib
system:java.runtime.name=Java(TM) SE Runtime Environment
system:java.runtime.version=1.8.0_361-b09
system:java.specification.maintenance.version=4
system:java.specification.name=Java Platform API Specification
system:java.specification.vendor=Oracle Corporation
system:java.specification.version=1.8
system:java.util.logging.config.file=/opt/hadoop/hive/conf/parquet-logging.properties
system:java.vendor=Oracle Corporation
system:java.vendor.url=http://java.oracle.com/
system:java.vendor.url.bug=http://bugreport.sun.com/bugreport/
system:java.version=1.8.0_361
system:java.vm.info=mixed mode
system:java.vm.name=Java HotSpot(TM) 64-Bit Server VM
system:java.vm.specification.name=Java Virtual Machine Specification
system:java.vm.specification.vendor=Oracle Corporation
system:java.vm.specification.version=1.8
system:java.vm.vendor=Oracle Corporation
system:java.vm.version=25.361-b09
system:line.separator=

system:log4j.configurationFile=hive-log4j2.properties
system:log4j2.formatMsgNoLookups=true
system:os.arch=amd64
system:os.name=Linux
system:os.version=5.15.108-1-pve
system:path.separator=:
system:proc_hivecli=
system:proc_jar=
system:sun.arch.data.model=64
system:sun.boot.class.path=/opt/java/jdk1.8.0_361/jre/lib/resources.jar:/opt/java/jdk1.8.0_361/jre/lib/rt.jar:/opt/java/jdk1.8.0_361/jre/lib/jsse.jar:/opt/java/jdk1.8.0_361/jre/lib/jce.jar:/opt/java/jdk1.8.0_361/jre/lib/charsets.jar:/opt/java/jdk1.8.0_361/jre/lib/jfr.jar:/opt/java/jdk1.8.0_361/jre/classes
system:sun.boot.library.path=/opt/java/jdk1.8.0_361/jre/lib/amd64
system:sun.cpu.endian=little
system:sun.cpu.isalist=
system:sun.io.unicode.encoding=UnicodeLittle
system:sun.java.command=org.apache.hadoop.util.RunJar /opt/hadoop/hive/lib/hive-cli-3.1.3.jar org.apache.hadoop.hive.cli.CliDriver -e SET;
system:sun.java.launcher=SUN_STANDARD
system:sun.jnu.encoding=ANSI_X3.4-1968
system:sun.management.compiler=HotSpot 64-Bit Tiered Compilers
system:sun.os.patch.level=unknown
system:user.country=US
system:user.dir=/home/ernestosegundo
system:user.home=/home/ernestosegundo
system:user.language=en
system:user.name=ernestosegundo
system:user.timezone=America/Lima
system:yarn.home.dir=/opt/hadoop
system:yarn.log.dir=/opt/hadoop/logs
system:yarn.log.file=hadoop.log
system:yarn.root.logger=INFO,console
WARN: The method class org.apache.commons.logging.impl.SLF4JLogFactory#release() was invoked.
WARN: Please see http://www.slf4j.org/codes.html#release for an explanation.
